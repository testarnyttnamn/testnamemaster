{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34371447",
   "metadata": {},
   "source": [
    "# DEMO notebook for GC-Spectro probe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa525ee",
   "metadata": {},
   "source": [
    "This notebook stands as a demonstration for the GC-Spectro probe, i.e. the multipoles $P_{\\rm gg}^{(\\ell)}(k,z)$ of the anisotropic galaxy power spectrum $P_{\\rm gg}(k,\\mu,z)$, which are defined as\n",
    "$$P_{\\rm gg}^{(\\ell)}(k,z) = \\frac{2\\ell+1}{2}\\int_{-1}^{+1}{\\rm d}\\mu'\\,P_{\\rm gg}(k',\\mu',z)\\,{\\cal L}_{\\ell}(\\mu')\\,,$$\n",
    "where ${\\cal L}_{\\ell}(\\mu)$ is the $\\ell$-th order Legendre polynomial, and Alcock-Paczynski corrections are properly included via the rescaling of the wavemode $k\\rightarrow k'$ and the pair orientation $\\mu\\rightarrow \\mu'$.\\\n",
    "The notebook shows how to obtain both linear and nonlinear predictions; in the latter case the only available model so far is the [EFT model](https://arxiv.org/abs/1909.05277)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ad6d5",
   "metadata": {},
   "source": [
    "### 1) Importing external modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcac84",
   "metadata": {},
   "source": [
    "First, we load the external modules needed to run the notebook:\\\n",
    "**numpy** --> for mathematical operations and handling of arrays,\\\n",
    "**time** --> for measuring time performances,\\\n",
    "**os, sys** --> for handling filenames, paths, and directories,\\\n",
    "**copy** --> for creating copies of Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "import os, sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a32b6",
   "metadata": {},
   "source": [
    "We also import **matplotlib**, and setup the default options for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('xtick', labelsize=15, direction='in')\n",
    "plt.rc('ytick', labelsize=15, direction='in')\n",
    "plt.rc('font', size=15)\n",
    "plt.rc('axes', titlesize=20)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('lines', markersize=6)\n",
    "plt.rc('legend', fontsize=15)\n",
    "plt.rc('mathtext', fontset='stix')\n",
    "plt.rc('font', family='STIXGeneral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c497b51",
   "metadata": {},
   "source": [
    "If you have cloned the repository, the location of this notebook should be in `likelihood-implementation/notebooks/`.\\\n",
    "Let's set the working directory to be `likelihood-implementation/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393870bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_path = os.path.realpath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, likelihood_path)\n",
    "print('Setting as working directory:', likelihood_path)\n",
    "print ('Conda environment:', os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a0494",
   "metadata": {},
   "source": [
    "### 2) Setup of the call to Cobaya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082302f4",
   "metadata": {},
   "source": [
    "We also import the `EuclidLikelihood` class, that contains the external likelihood of CLOE. This is stored within the module `cloe/cobaya_interface.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloe.cobaya_interface import EuclidLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b09f1",
   "metadata": {},
   "source": [
    "We are specifying this likelihood as an external likelihood class to be passed to Cobaya. In this case, Cobaya requires either a dictionary or a yaml file containing all the information necessary to run. Here, we set up the info dictionary. Since we are only interested in running GC-Spectro, all the nuisance parameters that refer to the 3x2pt observables are not used in the likelihood. However, we still need to specify them since we still don't have a switch to turn off the computation of unrequested probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    # 'params': Cobaya's protected key of the input dictionary. \n",
    "    # Includes the parameters that the user would like to sample over:\n",
    "    'params': {\n",
    "        ###########################\n",
    "        # Cosmological parameters #\n",
    "        ###########################\n",
    "        'tau': 0.0925,      # Optical depth\n",
    "        'H0': 67.0,         # Hubble parameter at z=0 [km/s/Mpc]\n",
    "        'omk': 0.0,         # Fractional curvature density\n",
    "        'ombh2': 0.022445,  # Physical baryon density\n",
    "        'omch2': 0.1205579, # Physical cold dark matter density\n",
    "        'mnu': 0.06,        # Sum of individual neutrino masses [eV]\n",
    "        'nnu': 3.046,       # Effective number of relativistic species\n",
    "        'w': -1,            # Dark energy equation of state at z=0\n",
    "        'wa': 0,            # Time-evolution of the dark energy equation of state (CLP parametrization)\n",
    "        'As': 2.12605e-9,   # Scalar amplitude of the primordial power spectrum\n",
    "        'ns': 0.96,         # Scalar index of the primordial power spectrum\n",
    "        'omegam': None,     # DERIVED parameter: fractional matter density\n",
    "        'omegab': None,     # DERIVED parameter: fractional baryon density\n",
    "        'omeganu': None,    # DERIVED parameter: fractional neutrino density\n",
    "        'omnuh2': None,     # DERIVED parameter: physical neutrino density\n",
    "        'omegac': None,     # DERIVED parameter: fractional cold dark matter density\n",
    "        'N_eff': None,      # DERIVED parameter: effective number of relativistic species\n",
    "        ##########################\n",
    "        # Photometric parameters #\n",
    "        ##########################\n",
    "        'b1_photo': 1.0997727037892875, 'b2_photo': 1.220245876862528, 'b3_photo': 1.2723993083933989, 'b4_photo': 1.316624471897739, 'b5_photo': 1.35812370570578,\n",
    "        'b6_photo': 1.3998214171814918, 'b7_photo': 1.4446452851824907, 'b8_photo': 1.4964959071110084, 'b9_photo': 1.5652475842498528, 'b10_photo': 1.7429859437184225,\n",
    "        # Magnification bias parameters\n",
    "        'magnification_bias_1': 0.0, 'magnification_bias_2': 0.0, 'magnification_bias_3': 0.0, 'magnification_bias_4': 0.0, 'magnification_bias_5': 0.0,\n",
    "        'magnification_bias_6': 0.0, 'magnification_bias_7': 0.0, 'magnification_bias_8': 0.0, 'magnification_bias_9': 0.0, 'magnification_bias_10': 0.0,\n",
    "        # Shear calibration multiplicative bias parameters                                                                                                                                                                                                                                                                                                            \n",
    "        'multiplicative_bias_1': 0.0, 'multiplicative_bias_2': 0.0, 'multiplicative_bias_3': 0.0, 'multiplicative_bias_4': 0.0, 'multiplicative_bias_5': 0.0,\n",
    "        'multiplicative_bias_6': 0.0, 'multiplicative_bias_7': 0.0, 'multiplicative_bias_8': 0.0, 'multiplicative_bias_9': 0.0, 'multiplicative_bias_10': 0.0,\n",
    "        # Intrinsic alignment parameters\n",
    "        'aia': 1.72,\n",
    "        'nia': -0.41,\n",
    "        'bia': 0.0,\n",
    "        # Redshift distributions nuisance parameters: shifts\n",
    "        'dz_1_GCphot': 0., 'dz_1_WL': 0., 'dz_2_GCphot': 0., 'dz_2_WL': 0., 'dz_3_GCphot': 0., 'dz_3_WL': 0., 'dz_4_GCphot': 0., 'dz_4_WL': 0., 'dz_5_GCphot': 0., 'dz_5_WL': 0.,\n",
    "        'dz_6_GCphot': 0., 'dz_6_WL': 0., 'dz_7_GCphot': 0., 'dz_7_WL': 0., 'dz_8_GCphot': 0., 'dz_8_WL': 0., 'dz_9_GCphot': 0., 'dz_9_WL': 0., 'dz_10_GCphot': 0., 'dz_10_WL': 0.,\n",
    "        ############################\n",
    "        # Spectroscopic parameters #\n",
    "        ############################\n",
    "        # Linear bias #\n",
    "        'b1_spectro_bin1': 1.46, 'b1_spectro_bin2': 1.61, 'b1_spectro_bin3': 1.75, 'b1_spectro_bin4': 1.90,\n",
    "        # Local quadratic bias #\n",
    "        'b2_spectro_bin1': 0.0, 'b2_spectro_bin2': 0.0, 'b2_spectro_bin3': 0.0, 'b2_spectro_bin4': 0.0,\n",
    "        # FOG counterterms #\n",
    "        'c0_spectro_bin1': 0.0, 'c0_spectro_bin2': 0.0, 'c0_spectro_bin3': 0.0, 'c0_spectro_bin4': 0.0,\n",
    "        'c2_spectro_bin1': 0.0, 'c2_spectro_bin2': 0.0, 'c2_spectro_bin3': 0.0, 'c2_spectro_bin4': 0.0,\n",
    "        'c4_spectro_bin1': 0.0, 'c4_spectro_bin2': 0.0, 'c4_spectro_bin3': 0.0, 'c4_spectro_bin4': 0.0,\n",
    "        # Deviations from Poisson shot-noise #\n",
    "        'aP_spectro_bin1': 0.0, 'aP_spectro_bin2': 0.0, 'aP_spectro_bin3': 0.0, 'aP_spectro_bin4': 0.0,\n",
    "        # Inverse number density #\n",
    "        'Psn_spectro_bin1': 0.0, 'Psn_spectro_bin2': 0.0, 'Psn_spectro_bin3': 0.0, 'Psn_spectro_bin4': 0.0,\n",
    "        # Growth index\n",
    "        'gamma_MG': 0.55\n",
    "    },\n",
    "    # 'likelihood': Cobaya's protected key of the input dictionary.\n",
    "    # Set up of the run, choice of data samples, flags, etc.\n",
    "    'likelihood': {\n",
    "        'Euclid': {\n",
    "            # Likelihood Class to be read as external\n",
    "            'external': EuclidLikelihood,\n",
    "            # Select which observables to use during the analysis (here only GCspectro)\n",
    "            'observables_selection': {\n",
    "                'WL': {\n",
    "                    'WL': False, 'GCphot': False, 'GCspectro': False\n",
    "                },\n",
    "                'GCphot': {\n",
    "                    'GCphot': False, 'GCspectro': False\n",
    "                },\n",
    "                'GCspectro': {\n",
    "                    'GCspectro': True\n",
    "                }\n",
    "            },         \n",
    "            # Plot the selected observables matrx\n",
    "            'plot_observables_selection': True,  \n",
    "            # Nonlinear flags to select which nonlinear model to adopt\n",
    "            # Available options are:\n",
    "            # a) NL_flag_phot_matter (nonlinear model of matter power spectrum for photometric probes)\n",
    "            #    0 -> linear theory\n",
    "            #    1 -> Takahashi\n",
    "            #    2 -> Mead2020 (w/o baryon corrections)\n",
    "            #    3 -> EE2\n",
    "            #    4 -> Bacco (matter)\n",
    "            # b) NL_flag_spectro (nonlinear model of galaxy power spectrum for GCspectro)\n",
    "            #    0 -> linear theory (linear matter evolution, linear bias, and Kaiser factor)\n",
    "            #    1 -> EFT\n",
    "            'NL_flag_phot_matter': 0,\n",
    "            'NL_flag_spectro': 0,\n",
    "            # 'data': This give specifications for the paths of the input data files\n",
    "            'data': { \n",
    "                # 'sample' specifies the first folder below the main data folder\n",
    "                'sample': 'ExternalBenchmark',\n",
    "                # 'spectro' and 'photo' specify paths to data files.\n",
    "                'spectro': {\n",
    "                    # GC Spectro root name should contain z{:s} string to enable iteration over bins\n",
    "                    'root': 'cov_power_galaxies_dk0p004_z{:s}.fits',\n",
    "                    'redshifts': [\"1.\", \"1.2\", \"1.4\", \"1.65\"],\n",
    "                    'edges': [0.9, 1.1, 1.3, 1.5, 1.8]\n",
    "                },\n",
    "                'photo': {\n",
    "                    'ndens_GC': 'niTab-EP10-RB00.dat',\n",
    "                    'ndens_WL': 'niTab-EP10-RB00.dat',\n",
    "                    'luminosity_ratio': 'luminosity_ratio.dat',\n",
    "                    # Photometric root names should contain z{:s} string to specify IA model\n",
    "                    'root_GC': 'Cls_{:s}_PosPos.dat',\n",
    "                    'root_WL': 'Cls_{:s}_ShearShear.dat',\n",
    "                    'root_XC': 'Cls_{:s}_PosShear.dat',\n",
    "                    'IA_model': 'zNLA',\n",
    "                    # Photometric covariances root names should contain z{:s} string to specify how the covariance was calculated\n",
    "                    'cov_GC': 'CovMat-PosPos-{:s}-20Bins.npy',\n",
    "                    'cov_WL': 'CovMat-ShearShear-{:s}-20Bins.npy',\n",
    "                    'cov_3x2pt': 'CovMat-3x2pt-{:s}-20Bins.npy',\n",
    "                    'cov_model': 'Gauss'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # 'theory': Cobaya's protected key of the input dictionary.\n",
    "    # Minimum theoretical requirements to a Boltzman Solver (CAMB in this case)\n",
    "    'theory': {\n",
    "        'camb': {\n",
    "            'stop_at_error': True, \n",
    "            'extra_args': {\n",
    "                'num_massive_neutrinos': 1,\n",
    "                'dark_energy_model': 'ppf'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # 'sampler': Cobaya's protected key of the input dictionary.\n",
    "    # In this DEMO, we use the 'evaluate' sampler to make a single computation of the posterior distributions\n",
    "    'sampler': {\n",
    "        'evaluate': None\n",
    "    },  \n",
    "    # 'output': Cobaya's protected key of the input dictionary.\n",
    "    # Defines path for output products\n",
    "    'output': 'chains/my_euclid_experiment',\n",
    "    # 'debug': Cobaya's protected key of the input dictionary.\n",
    "    # Level of detail of debug\n",
    "    'debug': False,\n",
    "    # 'timing': Cobaya's protected key of the input dictionary.\n",
    "    # Decides whether to print the time to compute the posterior distribution or not\n",
    "    'timing': True,\n",
    "    # 'force': Cobaya's protected key of the input dictionary.\n",
    "    # If True, Cobaya forces deleting the previous output files with the same name\n",
    "    'force': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25712e2",
   "metadata": {},
   "source": [
    "We need to call this method to update the `params.yaml` file that contains all the nuisance parameters of CLOE that would be otherwise unkwown to COBAYA. Here the update is based on the info dictionary defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f56324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloe.auxiliary.likelihood_yaml_handler import write_params_yaml_from_info_dict\n",
    "write_params_yaml_from_info_dict(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaae61",
   "metadata": {},
   "source": [
    "Now that the `params.yaml` is updated, we can pass the info dictionary to Cobaya. Since we want to access the internal quantities of our likelihood module, we are going to make use of the `model` object from Cobaya. From this object it is later possible to get all the information we want.\\\n",
    "Before that, we are setting the nonlinear model for the matter power spectrum coming from the Boltzmann solver according to the value of the nonlinear flag for the photometric probes, `NL_flag_photo_matter`. In this case, this is not necessary, since we are not using the photometric probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloe.auxiliary.likelihood_yaml_handler import set_halofit_version\n",
    "set_halofit_version(info, info['likelihood']['Euclid']['NL_flag_phot_matter'])\n",
    "\n",
    "from cobaya.model import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60546d8",
   "metadata": {},
   "source": [
    "The `get_model` function of Cobaya imported in the line above needs a yaml or dictionary as an argument, so we pass the one that we have defined in the previous cell. This function is going to initialize the `EuclidLikelihood` class. However, in order to have an updated instance of the class, in which all the requirements have been properly received from the Boltzmann solver, we need to make an evaluation of the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "model = get_model(info)\n",
    "print('Time for initialization of the likelihood: ', time.time()-t1)\n",
    "\n",
    "t1 = time.time()\n",
    "logposterior = model.logposterior({})\n",
    "print('Time for evaluation of the likelihood: ', time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27e0ad",
   "metadata": {},
   "source": [
    "**Please note:** even though we are not asking for the 3x2pt photomteric observables, the current version of CLOE initialises also the `Photo` class (the one dedicated to the calculations for the 3x2pt statistics), and therefore part of the time required for the evaluation of the likelihood is due to this extra time. This time is added to the evaluation of the likelihood and not to its initialization, since everything happens in the `update` method of the `Photo` class, which is called only when evaluating the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3a49f",
   "metadata": {},
   "source": [
    "Finally, we create an instance of `EuclidLikelihood`, and we pass to it all the attributes from the `model` wrapper defined in the previous cell. In this way, we are now allowed to access everything that is an attribute the `EuclidLikelihood` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51744695",
   "metadata": {},
   "outputs": [],
   "source": [
    "like = EuclidLikelihood()\n",
    "like.initialize()\n",
    "like.passing_requirements(model, info, **model.provider.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68563d",
   "metadata": {},
   "source": [
    "### 3) Plotting the spectroscopic galaxy power spectrum $P_{\\rm gg}(k,\\mu,z)$ (i.e. internal interpolator of the `Cosmology` class)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181a4e3",
   "metadata": {},
   "source": [
    "Here we set the arrays of wavelengths $k$, pair orientations $\\mu$, and redshifts $z$ used for the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.logspace(-3, 1, 200)\n",
    "mus = np.linspace(0.0, 1.0, 8)\n",
    "z = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d45f56",
   "metadata": {},
   "source": [
    "In order for the internal interpolators of CLOE to be updated, we need to run the `update_cosmo_dic` method of the `Cosmology` class. This will setup all the interpolators according to the current flags and parameters of the cosmo dictionary. In addition we save a deep copy of the cosmo dictionaries after the interpolators have been redefined, so that we can use them later to create instances of the `Spectro` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a293059",
   "metadata": {},
   "source": [
    "The first case we want corresponds to the original linear theory predictions, and therefore `NL_flag_spectro` is set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "like.cosmo.cosmo_dic['NL_flag_spectro'] = 0\n",
    "like.cosmo.update_cosmo_dic(like.cosmo.cosmo_dic['z_win'], 0.05)\n",
    "cosmo_dic_0 = copy.deepcopy(like.cosmo.cosmo_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6581d",
   "metadata": {},
   "source": [
    "The second case corresponds to the EFT model but with all the nuisance parameters set to 0. In this case, therefore, `NL_flag_spectro` is set to 1, and we manually set the extra EFT parameters to 0 (they are already set to 0, from the definition of the info dictionary, but we do it again in case this cell is run ahgain after the next one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b70a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "like.cosmo.cosmo_dic['NL_flag_spectro'] = 1\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['b2_spectro_bin1'] = 0.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c0_spectro_bin1'] = 0.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c2_spectro_bin1'] = 0.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c4_spectro_bin1'] = 0.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['aP_spectro_bin1'] = 0.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['Psn_spectro_bin1'] = 0.0\n",
    "like.cosmo.update_cosmo_dic(like.cosmo.cosmo_dic['z_win'], 0.05)\n",
    "cosmo_dic_1 = copy.deepcopy(like.cosmo.cosmo_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f972f5",
   "metadata": {},
   "source": [
    "The third case corresponds once again to the EFT model, but with the extra nuisance parameters no longer set to 0. This is going to show that the interpolator for $P_{\\rm gg}(k,\\mu,z)$ correctly sees modifications in the values of these parameters. The choice of the parameters here is arbitrary. We only provide an example for the first redshift bin, but this can be easily extended to other redshifts simply by modifying the corresponding nuisance parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate a cosmo dictionary with EFT with some values for the nuisance parameters\n",
    "like.cosmo.cosmo_dic['NL_flag_spectro'] = 1\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['b2_spectro_bin1'] = -0.2\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c0_spectro_bin1'] = 1.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c2_spectro_bin1'] = 1.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['c4_spectro_bin1'] = 1.0\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['aP_spectro_bin1'] = 0.5\n",
    "like.cosmo.cosmo_dic['nuisance_parameters']['Psn_spectro_bin1'] = 1000.0\n",
    "like.cosmo.update_cosmo_dic(like.cosmo.cosmo_dic['z_win'], 0.05)\n",
    "cosmo_dic_2 = copy.deepcopy(like.cosmo.cosmo_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a3bd6",
   "metadata": {},
   "source": [
    "The EFT model still features deviations from linear theory predictions even with all the higher-order parameters set to zero. This happens because there are extra one-loop contributions to the power spectrum that comes from the auto-correlation of the velocity divergence field with itself, and these are quantities that are not rescaled by a bias parameter. Let's see it directly in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(11,5))\n",
    "\n",
    "for i in range(len(mus)):\n",
    "    \n",
    "    ind1 = int(np.floor(i/4.0))\n",
    "    ind2 = i-ind1*4\n",
    "    ax = axs[ind1,ind2]\n",
    "    \n",
    "    mu = mus[i]\n",
    "    \n",
    "    ax.grid(ls='--', lw=0.3)\n",
    "\n",
    "    if ind1==0 and ind2==0:\n",
    "        ax.loglog(ks, cosmo_dic_0['Pgg_spectro'](z, ks, mu), lw=3, label='Linear theory')\n",
    "        ax.loglog(ks, cosmo_dic_1['Pgg_spectro'](z, ks, mu), lw=3, label='EFT (all params = 0)')\n",
    "        ax.loglog(ks, cosmo_dic_2['Pgg_spectro'](z, ks, mu), lw=3, label='EFT')\n",
    "    else:\n",
    "        ax.loglog(ks, cosmo_dic_0['Pgg_spectro'](z, ks, mu), lw=3)\n",
    "        ax.loglog(ks, cosmo_dic_1['Pgg_spectro'](z, ks, mu), lw=3)\n",
    "        ax.loglog(ks, cosmo_dic_2['Pgg_spectro'](z, ks, mu), lw=3)\n",
    "\n",
    "    ax.set_ylim([0.1, 3e5])\n",
    "    \n",
    "    if ind2==0:\n",
    "        ax.set_ylabel(r'$P_{\\rm gg}(k) \\, \\left[{\\rm Mpc}^3\\right]$')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    " \n",
    "    if ind1==1:\n",
    "        ax.set_xlabel(r'$k \\, \\left[{\\rm Mpc}^{-1}\\right]$')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    ax.set_xticks([0.01, 1])\n",
    "    ax.set_xticklabels(['0.01', '1'])\n",
    "    \n",
    "    ax.text(0.4, 3e4, r'$\\mu=%.2f$'%(mu), size=12, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "fig.legend(prop={'size':14}, ncol=3, loc='upper center')\n",
    "fig.subplots_adjust(wspace=0.01, hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da54cc5",
   "metadata": {},
   "source": [
    "The different amplitude as a function of the value of $\\mu$ highlights the anisotropic signal introduced by redshift-space distortions, increasing towards higher values of $\\mu$, i.e. along the line of sight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0dda1",
   "metadata": {},
   "source": [
    "### 4) Plotting the galaxy power spectrum multipoles $P^{(\\ell)}(k,z)$ (i.e. the main deliverable of the `Spectro` class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cb6bb5",
   "metadata": {},
   "source": [
    "Now, we check directly the galaxy power spectrum multipoles using the `Spectro` class. We could have used the instance of `Spectro` that is already contained as an attribute of `like`, similarly to what we did for the instance of `Cosmology`, but here we want to show how to use the `Spectro` class from the very beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a424b",
   "metadata": {},
   "source": [
    "First, we create three separate instances of `Spectro`, one for each of the cases defined above. The `Spectro` class requires two arguments to be instantiated. The first one is a cosmo dictionary, with the internal interpolators already up to date. The second is a list of spectroscopic bin centers, to correct for the purity of the sample. Here we pass respectively the three deep copies of the cosmo dictionary defined above, and the values of the bin centers defined in the info dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloe.spectroscopic_survey.spectro import Spectro\n",
    "\n",
    "spec_ins_0 = Spectro(cosmo_dic_0, info['likelihood']['Euclid']['data']['spectro']['redshifts'])\n",
    "spec_ins_1 = Spectro(cosmo_dic_1, info['likelihood']['Euclid']['data']['spectro']['redshifts'])\n",
    "spec_ins_2 = Spectro(cosmo_dic_2, info['likelihood']['Euclid']['data']['spectro']['redshifts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84e176",
   "metadata": {},
   "source": [
    "Then we call the method `multipole_spectra` of the `Spectro` class to compute the multipoles of order 0,2,4 (i.e. monopole, quadrupole, and hexadecapole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_0_0 = np.empty(len(ks))\n",
    "mps_0_2 = np.empty(len(ks))\n",
    "mps_0_4 = np.empty(len(ks))\n",
    "for i in range(len(ks)):\n",
    "    mps_0_0[i], mps_0_2[i], mps_0_4[i] = spec_ins_0.multipole_spectra(z, ks[i], ms=[0,2,4])\n",
    "    \n",
    "mps_1_0 = np.empty(len(ks))\n",
    "mps_1_2 = np.empty(len(ks))\n",
    "mps_1_4 = np.empty(len(ks))\n",
    "for i in range(len(ks)):\n",
    "    mps_1_0[i], mps_1_2[i], mps_1_4[i] = spec_ins_1.multipole_spectra(z, ks[i], ms=[0,2,4])\n",
    "    \n",
    "mps_2_0 = np.empty(len(ks))\n",
    "mps_2_2 = np.empty(len(ks))\n",
    "mps_2_4 = np.empty(len(ks))\n",
    "for i in range(len(ks)):\n",
    "    mps_2_0[i], mps_2_2[i], mps_2_4[i] = spec_ins_2.multipole_spectra(z, ks[i], ms=[0,2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea67895",
   "metadata": {},
   "source": [
    "Finally, we plot the multipoles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.grid(ls='--', lw=0.3)\n",
    "ax.loglog(ks, mps_0_0, lw=3, label=r'$\\ell=0$')\n",
    "ax.loglog(ks, mps_0_2, lw=3, label=r'$\\ell=2$')\n",
    "ax.loglog(ks, mps_0_4, lw=3, label=r'$\\ell=4$')\n",
    "ax.set_ylim([0.01, 3e5])\n",
    "ax.set_xticks([0.01, 1])\n",
    "ax.set_xticklabels(['0.01', '1'])\n",
    "ax.set_ylabel(r'$P_{\\rm gg}^{(\\ell)}(k) \\, \\left[{\\rm Mpc}^3\\right]$')\n",
    "ax.set_xlabel(r'$k \\, \\left[{\\rm Mpc}^{-1}\\right]$')\n",
    "ax.text(0.001, 0.03, 'Linear theory', size=14, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "ax = axs[1]\n",
    "ax.grid(ls='--', lw=0.3)\n",
    "ax.loglog(ks, mps_1_0, lw=3)\n",
    "ax.loglog(ks, mps_1_2, lw=3)\n",
    "ax.loglog(ks, mps_1_4, lw=3)\n",
    "ax.set_ylim([0.01, 3e5])\n",
    "ax.set_xticks([0.01, 1])\n",
    "ax.set_xticklabels(['0.01', '1'])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xlabel(r'$k \\, \\left[{\\rm Mpc}^{-1}\\right]$')\n",
    "ax.text(0.001, 0.03, 'EFT (all params = 0)', size=14, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "ax = axs[2]\n",
    "ax.grid(ls='--', lw=0.3)\n",
    "ax.loglog(ks, mps_2_0, lw=3)\n",
    "ax.loglog(ks, mps_2_2, lw=3)\n",
    "ax.loglog(ks, mps_2_4, lw=3)\n",
    "ax.set_ylim([0.01, 3e5])\n",
    "ax.set_xticks([0.01, 1])\n",
    "ax.set_xticklabels(['0.01', '1'])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xlabel(r'$k \\, \\left[{\\rm Mpc}^{-1}\\right]$')\n",
    "ax.text(0.001, 0.03, 'EFT', size=14, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "fig.legend(prop={'size':14}, ncol=3, loc='upper center')\n",
    "fig.subplots_adjust(wspace=0.01, hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55427a7",
   "metadata": {},
   "source": [
    "### 5) Timing different modelling options for GCspectro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90142b8",
   "metadata": {},
   "source": [
    "Now, we measure the speed for an evaluation of the likelihood when only considering the GCspectro probe. At the moment we only test the linear case (`NL_flag_spectro=0`) and the EFT case (`NL_flag_spectro=1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8390560",
   "metadata": {},
   "source": [
    "We create a copy of the info dictionary and modify some of its arguments, i.e. the nonlinear flag, and the parameter $n_{\\rm s}$ (since we want to sample over it). Then we create an instance of a Cobaya model, as we did in the previous cells, and we measure the speed for the evaluation of the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First copy the info dict \n",
    "info_speed = info.copy()\n",
    "\n",
    "# We measure the time it takes for a posterior evaluation. Arbitrarily, we choose to sample ns.\n",
    "info_speed['params']['ns'] = {'prior':{'min':0.95, 'max':0.97}}\n",
    "\n",
    "# We start with NL_flag_phot_matter = 0\n",
    "info_speed['likelihood']['Euclid']['NL_flag_spectro'] = 0\n",
    "\n",
    "model_speed = get_model(info_speed)\n",
    "\n",
    "# Evaluate posterior once to ensure that everything is loaded before measuring time\n",
    "point = dict(zip(model_speed.parameterization.sampled_params(),\n",
    "                 model_speed.prior.sample(ignore_external=True)[0]))\n",
    "logposterior = model_speed.logposterior(point)\n",
    "\n",
    "# Evalute posterior n_eval times and average\n",
    "\n",
    "n_eval = 10\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for i in range(n_eval):\n",
    "    point = dict(zip(model_speed.parameterization.sampled_params(),\n",
    "                     model_speed.prior.sample(ignore_external=True)[0]))\n",
    "\n",
    "    logposterior = model_speed.logposterior(point)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\nAverage time for posterior evaluation for NL_spectro =\",info_speed['likelihood']['Euclid']['NL_flag_spectro'],\n",
    "      \"is\",(t2-t1)/n_eval,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with NL_flag_phot_matter = 0\n",
    "info_speed['likelihood']['Euclid']['NL_flag_spectro'] = 1\n",
    "\n",
    "model_speed = get_model(info_speed)\n",
    "\n",
    "# Evaluate posterior once to ensure that everything is loaded before measuring time\n",
    "point = dict(zip(model_speed.parameterization.sampled_params(),\n",
    "                 model_speed.prior.sample(ignore_external=True)[0]))\n",
    "logposterior = model_speed.logposterior(point)\n",
    "\n",
    "# Evalute posterior n_eval times and average\n",
    "\n",
    "n_eval = 10\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for i in range(n_eval):\n",
    "    point = dict(zip(model_speed.parameterization.sampled_params(),\n",
    "                     model_speed.prior.sample(ignore_external=True)[0]))\n",
    "\n",
    "    logposterior = model_speed.logposterior(point)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"\\nAverage time for posterior evaluation for NL_spectro =\",info_speed['likelihood']['Euclid']['NL_flag_spectro'],\n",
    "      \"is\",(t2-t1)/n_eval,\"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdb58f",
   "metadata": {},
   "source": [
    "**Please note:** similarly to the evaluation of the likelihood that happens at the beginning of this notebook, the time provided here also includes an extra contribution due to the initialisation of the `Photo` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bc6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

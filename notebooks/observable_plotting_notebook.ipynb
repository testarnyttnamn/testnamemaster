{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observable Plotting Notebook\n",
    "\n",
    "This notebook demonstrates how the auxiliary plotting functions work. These functions require only a full cosmology dictionary of the type described in `likelihood.cosmo.cosmology` to function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "First, we import the required modules, and set-up a mock cosmology dictionary, using existing external benchmark files, and, where necessary `CAMB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import camb\n",
    "\n",
    "from astropy import constants as const\n",
    "from scipy import interpolate\n",
    "from likelihood.auxiliary.plotter import Plotter\n",
    "from likelihood.cosmo.cosmology import Cosmology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the matter power spectrum used to generate the Weak Lensing benchmark. Here, a dummy class is created to make sure the matter power spectrum interpolator has the same format as a `CAMB` power spectrum interpolator. <span style=\"color:red\"> **Note:** </span> As the the provided power spectrum file only covers z up to 2.5. The code requires the power spectrum to be evaluated up to z=4. Accordingly, `CAMB` is used to create the matter power spectrum used in this notebook, below. However, we leave this in to demonstrate how an external power spectrum could be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_file = np.loadtxt('../data/ExternalBenchmark/Photometric/Pnl-TB-LCDM.dat')\n",
    "ks = 10**P_file[:, 0]\n",
    "zs = P_file[:, 1]\n",
    "P_lin = 10**P_file[:, 3]\n",
    "zk = np.concatenate((zs.reshape(-1,1),ks.reshape(-1,1)), axis=1)\n",
    "P_interp = interpolate.LinearNDInterpolator(zk, P_lin)\n",
    "\n",
    "\n",
    "class mock_P_obj:\n",
    "    def __init__(self, p_interp):\n",
    "        self.P = p_interp\n",
    "\n",
    "\n",
    "test_P = mock_P_obj(P_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the comoving distance and Hubble function are loaded, and the angular diameter distance is calculated assuming flatness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmov_file = np.loadtxt('../data/ExternalBenchmark/Photometric/ComDist-LCDM-Lin-noIA.dat')\n",
    "zs_r = cmov_file[:, 0]\n",
    "rs = cmov_file[:, 1]\n",
    "ang_dists = rs/(1.0 + zs_r)\n",
    "\n",
    "rz_interp = interpolate.InterpolatedUnivariateSpline(x=zs_r, y=rs, ext=0)\n",
    "dz_interp = interpolate.InterpolatedUnivariateSpline(x=zs_r, y=ang_dists, ext=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hz_file = np.loadtxt('../data/ExternalBenchmark/Photometric/Hz.dat')\n",
    "zs_H = Hz_file[:, 0]\n",
    "Hs = Hz_file[:, 1]\n",
    "\n",
    "Hs_mpc = Hz_file[:, 1] / const.c.to('km/s').value\n",
    "\n",
    "Hz_interp = interpolate.InterpolatedUnivariateSpline(x=zs_H, y=Hs,\n",
    "                                                     ext=0)\n",
    "\n",
    "Hmpc_interp = interpolate.InterpolatedUnivariateSpline(x=zs_H,\n",
    "                                                       y=Hs_mpc,\n",
    "                                                       ext=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modified gravity sigma function that is always 1 is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MG_vals = np.ones_like(ks)\n",
    "MG_interp = interpolate.LinearNDInterpolator(zk, MG_vals, fill_value=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a mock cosmology dictionary, following the structure in `likelihood.cosmo.cosmology`, and fill it with quantities that are already known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_cosmo_dic = {\n",
    "                'H0': 67.0,\n",
    "                'omch2': 0.121203,\n",
    "                'ombh2': 0.022445,\n",
    "                'ns': 0.96,\n",
    "                'sigma_8_0': 0.816,\n",
    "                'As': 2.115e-9,\n",
    "                'w': -1.0,\n",
    "                'omkh2': 0.0,\n",
    "                'omnuh2': 0.0,\n",
    "                'c': const.c.to('km/s').value,\n",
    "                'r_z_func': rz_interp,\n",
    "                'd_z_func': dz_interp,\n",
    "                'H_z_func': Hz_interp,\n",
    "                'H_z_func_Mpc': Hmpc_interp,\n",
    "                'z_win': np.linspace(0.0, 4.0, 100),\n",
    "                'k_win': np.linspace(0.001, 10.0, 100),\n",
    "                'MG_sigma': MG_interp}\n",
    "\n",
    "mock_cosmo_dic['H0_Mpc'] = \\\n",
    "    mock_cosmo_dic['H0'] / const.c.to('km/s').value\n",
    "mock_cosmo_dic['Omb'] = \\\n",
    "    mock_cosmo_dic['ombh2'] / (mock_cosmo_dic['H0'] / 100.)**2.\n",
    "mock_cosmo_dic['Omc'] = \\\n",
    "    mock_cosmo_dic['omch2'] / (mock_cosmo_dic['H0'] / 100.)**2.\n",
    "mock_cosmo_dic['Omnu'] = \\\n",
    "    mock_cosmo_dic['omnuh2'] / (mock_cosmo_dic['H0'] / 100.)**2.\n",
    "mock_cosmo_dic['Omm'] = (mock_cosmo_dic['Omnu'] +\n",
    "                         mock_cosmo_dic['Omc'] +\n",
    "                         mock_cosmo_dic['Omb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use `CAMB` to calculate the missing quantities; in particular, sigma_8 and fsigma_8. These are also added to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: redshifts have been re-sorted (earliest first)\n"
     ]
    }
   ],
   "source": [
    "cp = camb.set_params(ns=mock_cosmo_dic['ns'], H0=mock_cosmo_dic['H0'],\n",
    "                             ombh2=mock_cosmo_dic['ombh2'],\n",
    "                             omch2=mock_cosmo_dic['omch2'], w=-1.0,\n",
    "                             omk=0.0,\n",
    "                             wa=0.0, lmax=5000, WantTransfer=True,\n",
    "                             dark_energy_model='DarkEnergyPPF', mnu=0.06,\n",
    "                             As=mock_cosmo_dic['As'], TCMB=2.726, YHe=0.25, kmax=100.0,\n",
    "                             redshifts=np.linspace(0.0, 5.0, 50).tolist())\n",
    "results = camb.get_results(cp)\n",
    "power = results.get_matter_power_interpolator(nonlinear=False, hubble_units=False, k_hunit=False)\n",
    "sig_8_arr = results.get_sigma8()\n",
    "sig_8_interp = interpolate.InterpolatedUnivariateSpline(x=np.linspace(0.0, 5.0, 50), y=sig_8_arr[::-1], ext=0)\n",
    "f_sig_8_arr = results.get_fsigma8()\n",
    "f_sig_8_interp = interpolate.InterpolatedUnivariateSpline(x=np.linspace(0.0, 5.0, 50), y=f_sig_8_arr[::-1], ext=0)\n",
    "mock_cosmo_dic['Pk_interpolator'] = power\n",
    "mock_cosmo_dic['Pk_delta'] = power\n",
    "mock_cosmo_dic['sigma8_z_func'] = sig_8_interp\n",
    "mock_cosmo_dic['fsigma8_z_func'] = f_sig_8_interp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to enable plotting of both Galaxy Clustering probes, we need the various galaxy power spectra. These are calculated with the mock cosmology dictionary, together with the existing functions within the `cosmology` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_ins = Cosmology()\n",
    "cos_ins.cosmo_dic.update(mock_cosmo_dic)\n",
    "mock_cosmo_dic['Pgg_spec'] = cos_ins.Pgg_spec_def\n",
    "mock_cosmo_dic['Pgdelta_spec'] = cos_ins.Pgd_spec_def\n",
    "mock_cosmo_dic['Pgg_phot'] = cos_ins.Pgg_phot_def\n",
    "mock_cosmo_dic['Pgdelta_phot'] = cos_ins.Pgd_phot_def\n",
    "mock_cosmo_dic['Pgi_phot'] = cos_ins.Pgi_phot_def\n",
    "mock_cosmo_dic['Pii'] = cos_ins.Pii_def\n",
    "mock_cosmo_dic['Pdeltai'] = cos_ins.Pdeltai_def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save various quantites that may be useful later, if we would like to run only the photometric or spectroscopic modules of the code without calculating cosmological quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = '../likelihood/tests/test_input/'\n",
    "np.save(test_data+'f_sig_8_arr.npy', f_sig_8_arr)\n",
    "np.save(test_data+'sig_8_arr.npy', sig_8_arr)\n",
    "\n",
    "z_min = 0.0\n",
    "z_max = 4.0\n",
    "z_samp = 100\n",
    "zs_base = np.linspace(z_min, z_max, z_samp)\n",
    "\n",
    "k_samp_GC = 100\n",
    "k_min_GC_phot_interp = 0.001\n",
    "k_max_GC_phot_interp = 10.0\n",
    "ks_base = np.logspace(np.log10(k_min_GC_phot_interp),\n",
    "                         np.log10(k_max_GC_phot_interp),\n",
    "                         k_samp_GC)\n",
    "pdeltadelta_phot = np.array([power.P(zz, ks_base) for zz in zs_base])\n",
    "pgg_phot = np.array([cos_ins.Pgg_phot_def(zz, ks_base) for zz in zs_base])\n",
    "pgdelta_phot = np.array([cos_ins.Pgd_phot_def(zz, ks_base)\n",
    "                         for zz in zs_base])\n",
    "pii = np.array([cos_ins.Pii_def(zz, ks_base) for zz in zs_base])\n",
    "pdeltai = np.array([cos_ins.Pdeltai_def(zz, ks_base) for zz in zs_base])\n",
    "pgi_phot = np.array([cos_ins.Pgi_phot_def(zz, ks_base) for zz in zs_base])\n",
    "pgi_spec = np.array([cos_ins.Pgi_spec_def(zz, ks_base) for zz in zs_base])\n",
    "\n",
    "np.save(test_data+'pdd.npy', pdeltadelta_phot)\n",
    "np.save(test_data+'pgg.npy', pgg_phot)\n",
    "np.save(test_data+'pgd.npy', pgdelta_phot)\n",
    "np.save(test_data+'pii.npy', pii)\n",
    "np.save(test_data+'pdi.npy', pdeltai)\n",
    "np.save(test_data+'pgi_phot.npy', pgi_phot)\n",
    "np.save(test_data+'pgi_spec.npy', pgi_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood.photometric_survey import photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the plotting routines\n",
    "\n",
    "Now, we can straightforwardly use the auxiliary plotting routines. To use these, we first create `matplotlib.pyplot` axis objects, and then pass these to the relevant plotting functions, together with out specified cosmology dictionary. The functions can also allow the specification of `matplotlib` colours and linestyles using the `pl_colour` and `pl_linestyle` parameters. Custom labels for each individual plot can be specified with `pl_label`. Please see the function API for more details.\n",
    "\n",
    "This allows greater flexibility to the user in how they want to plot the various combinations of observables. Accordingly, any axis scaling/labelling must be done after the functions are called. \n",
    "\n",
    "An example for each observable is given below. Also shown is how to plot the external benchmark/OULE3 values together with the error bars from the covariance matrix.\n",
    "\n",
    "### Weak Lensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "n(z) files not found. Please, check out the files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/likelihood/lib/python3.6/site-packages/likelihood-0.0.0-py3.6.egg/likelihood/data_reader/reader.py\u001b[0m in \u001b[0;36mreader_raw_nz\u001b[0;34m(self, file_dest, file_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# (GCH): open file and read the content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdat_dir_main\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_dest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/local/home/scasas/anaconda2/envs/likelihood/lib/python3.6/site-packages/likelihood-0.0.0-py3.6.egg/data/ExternalBenchmark/Photometric/niTab-EP10-RB00.dat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bff7ca3e97e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpl_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosmo_dic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmock_cosmo_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_external_Cl_phot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/likelihood/lib/python3.6/site-packages/likelihood-0.0.0-py3.6.egg/likelihood/auxiliary/plotter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cosmo_dic)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosmo_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosmo_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_nz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_GC_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_phot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/likelihood/lib/python3.6/site-packages/likelihood-0.0.0-py3.6.egg/likelihood/data_reader/reader.py\u001b[0m in \u001b[0;36mcompute_nz\u001b[0;34m(self, file_dest, file_name_GC, file_name_WL)\u001b[0m\n\u001b[1;32m    104\u001b[0m         self.nz_dict_GC_Phot_raw.update(\n\u001b[1;32m    105\u001b[0m             self.reader_raw_nz(\n\u001b[0;32m--> 106\u001b[0;31m                 file_dest, file_name_GC))\n\u001b[0m\u001b[1;32m    107\u001b[0m         self.nz_dict_GC_Phot.update(\n\u001b[1;32m    108\u001b[0m             {\n",
      "\u001b[0;32m~/anaconda2/envs/likelihood/lib/python3.6/site-packages/likelihood-0.0.0-py3.6.egg/likelihood/data_reader/reader.py\u001b[0m in \u001b[0;36mreader_raw_nz\u001b[0;34m(self, file_dest, file_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             raise Exception(\n\u001b[0;32m---> 83\u001b[0;31m                 'n(z) files not found. Please, check out the files')\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     def compute_nz(self,\n",
      "\u001b[0;31mException\u001b[0m: n(z) files not found. Please, check out the files"
     ]
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "\n",
    "pl_inst = Plotter(cosmo_dic=mock_cosmo_dic)\n",
    "\n",
    "ax1 = pl_inst.plot_external_Cl_phot(2, 3, ax1, probe='WL')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), 2, 3, ax1, probe='WL', pl_colour='r', pl_linestyle='--')\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=16)\n",
    "ax1.set_ylabel(r'$C_\\ell$', fontsize=16)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photometric Galaxy Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "\n",
    "ax1 = pl_inst.plot_external_Cl_phot(1, 1, ax1, probe='GC-Phot')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), 1, 1, ax1, probe='GC-Phot', pl_colour='r', pl_linestyle='--')\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=16)\n",
    "ax1.set_ylabel(r'$C_\\ell$', fontsize=16)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Lensing x Photometric Galaxy Clustering Cross-spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "\n",
    "ax1 = pl_inst.plot_external_Cl_XC(3, 3, ax1)\n",
    "ax1 = pl_inst.plot_Cl_XC(np.logspace(1, 3.6, 10), 3, 3, ax1, pl_colour='r', pl_linestyle='--')\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=16)\n",
    "ax1.set_ylabel(r'$C_\\ell$', fontsize=16)\n",
    "ax1.set_xscale('log')\n",
    "#ax1.set_yscale('log')\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectroscopic Galaxy Clustering\n",
    "\n",
    "Note: The internal and external spectra are currently plotted seperately due to the fact that the external spectra are supplied in different units. Once this is corrected, this notebook should be editted to place both on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "\n",
    "ax1 = pl_inst.plot_external_GC_spec(\"1.2\", 2, ax1, pl_label='a')\n",
    "ax1 = pl_inst.plot_GC_spec_multipole(1.2, np.logspace(-2.6, -0.31), 2, ax1, pl_colour='r', pl_linestyle='--')\n",
    "ax1.set_xlabel(r'$k$', fontsize=16)\n",
    "ax1.set_ylabel(r'$P_\\ell$', fontsize=16)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

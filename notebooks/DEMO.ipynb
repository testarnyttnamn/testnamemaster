{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO: CLOE\n",
    "\n",
    "**Description**: this DEMO allows the user to compute the theoretical predictions of the galaxy clustering and weak gravitational lensing probes along with the likelihood given some benchmark data. This notebook uses `CLOE` along with `Cobaya`.\n",
    "\n",
    "It contains three potential different scenarios for the user (referred to as user-cases) corresponding to CASE 1, 2 and 3 in the notebook. A basic description of each of the user-cases is the following:\n",
    "\n",
    "* **CASE 1**: samples the posterior distribution of the parameters of interest (cosmological and nuisance parameters) by running `Cobaya` with the external Euclid Likelihood of `CLOE` and the sampler of choice from `Cobaya`. At the moment, this user-case executes a single point evaluation of the likelihood using the `evaluate` sampler of `Cobaya`.\n",
    "\n",
    "* **CASE 2**: creates a `model` of `Cobaya` using an internal wrapper of `Cobaya` itself. This wrapper is based on the `evaluate` sampler of `Cobaya`. The `model` allows the user to make a single computation of the priors, likelihood, and posterior, measure the time needed by each module or retrieve the information of which theoretical quantities were asked to the Boltzman solvers, for instance. This `model` instance is important, because it is the way the connection between `Cobaya` and the `EuclidLikelihood` code is made internally within `cobaya_interface.py`. In fact, the `model` instance is essential if you want to run CASE 2.1.\n",
    "\n",
    "* **CASE 2.1**: the final section of the notebook retrieves and plots internal theoretical quantities computed by the `CLOE` code. Be aware that, to be able to retrieve and plot quantities, you need to first run **CASE 2**, because CASE 2.1 requires the `model` instance to be loaded. You can plot the following quantities:\n",
    "    * $H(z)$: Hubble parameter\n",
    "    * $r(z)$, $D_A(z)$: comoving and angular diameter distances\n",
    "    * $\\sigma_8$, $f\\sigma_8$: amplitude of the (linear) matter power spectrum on scales of 8 $h^{-1}$ Mpc and its product with the growth rate\n",
    "    * $D(z)$, $f(z)$: growth factor and growth rate\n",
    "    * $P_{\\delta\\delta}, P_{gg}, P_{g\\delta}, P_{\\delta i}, P_{gi}, P_{ii}$: matter power spectrum obtained by the Boltzman solver, and retrieved from `Cobaya`, and different power spectra\n",
    "    * $n(z)$: galaxy density distributions\n",
    "    * $W_i^{\\rm GC}(z), W_i^{\\rm \\gamma}(z), W_i^{\\rm IA}(z), W_i^{\\rm RSD}(z), W_i^{\\rm mag}(z)$ : window functions for galaxy clustering (GC), shear ($\\gamma$), intrinsic alignments (IA), redshift space distortions (RSD), and magnification bias (mag).\n",
    "    * $C_\\ell$: angular power spectra\n",
    "    * $P_\\ell$: Legendre multipole power spectra\n",
    "\n",
    "\n",
    "**README**: https://gitlab.euclid-sgs.uk/pf-ist-likelihood/likelihood-implementation/-/blob/master/README.md\n",
    "\n",
    "**Install**: in order to use this DEMO notebook, you need to clone the repository `https://gitlab.euclid-sgs.uk/pf-ist-likelihood/likelihood-implementation.git`, and install CLOE as described in the README.\n",
    "Alternatively, you may be ready to run if ```Cobaya``` and ```CAMB/CLASS``` are installed. See details below. \n",
    "\n",
    "**Cobaya documentation**: https://cobaya.readthedocs.io/en/latest/\n",
    "\n",
    "**Python information**: if the user is not comfortable with some Python vocabulary used in this notebook,\n",
    "a nice python review can be found here: https://wiki.python.org/moin/BeginnersGuide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General Python imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have cloned the repository and opened this notebook,\n",
    "# this notebook should be in likelihood-implementation/notebooks\n",
    "# Let's set the working directory to be likelihood-implementation\n",
    "\n",
    "likelihood_path = os.path.realpath(os.path.join(os.getcwd(),'..'))\n",
    "sys.path.insert(0, likelihood_path)\n",
    "print('Setting as working directory: ', likelihood_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matplotlib params setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.rc('font',size=25)\n",
    "plt.rc('axes', titlesize=26)\n",
    "plt.rc('axes', labelsize=25)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('lines', markersize=6)\n",
    "plt.rc('legend', fontsize=20)\n",
    "plt.rc('mathtext', fontset='stix')\n",
    "plt.rc('font', family='STIXGeneral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cobaya` needs some modules to run: i.e: `CAMB`, `CLASS`, `Polychord`, other likelihood codes, and data (Planck 2018, DES, ...)\n",
    "If you have installed `CLOE` as in the README instructions, you need to activate the conda environment `cloe` to run this notebook. This conda environment has CAMB/CLASS/Nonlinear codes installed, so you do not need to worry about anything else.\n",
    "\n",
    "Alternatively, if you have already installed Cobaya and other cosmological codes such as CAMB, CLASS, Polychord, or Planck 2018, you have two options. Be aware that we **discourage** to go with these two options at the moment:\n",
    "\n",
    "* **(1) Only for CAMB/CLASS in the `theory` block, Polychord in the `mcmc` block and `plik` in the `likelihood` block**:  point out where each of them is installed with the flag 'path' in the dictionary of Cell 5. See the comment in Cell 5 corresponding to the 'theory' key of the 'info' dictionary. If CLOE was not installed with conda, be aware that the Bacco emulator `baccoemu` and the Euclid emulator `euclidemu2` will need to be installed globally or locally by `pip install the_emulator (--user)` where `the_emulator` is `baccoemu`/`euclidemu2`. The flag `--user` makes pip install the package locally and it may be needed when runnning in a computer/cluster with no superuser permissions.\n",
    " \n",
    "\n",
    "* **(2) Only if you have CAMB/CLASS/Polychord installed automatically by Cobaya**: if you installed the cosmological codes as Cobaya automatic installation suggests  (https://cobaya.readthedocs.io/en/latest/installation_cosmo.html) you need to point out the path to your modules as in the variable `packages_path` below. If CLOE was not installed with conda, please be aware that you will need to have  `baccoemu` and `euclidemu2` installed globally or locally to use these emulators. See (1) for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ATTENTION: write down the path to your COBAYA modules if you want to follow option (2) above.\n",
    "# Otherwise skip this cell\n",
    "# packages_path = \"YOUR_PATH_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ATTENTION: turn to True if you would like to save all plots in a repository called figs\n",
    "if not os.path.exists('figs/'):\n",
    "    os.mkdir('figs/')\n",
    "save_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 1: Run `Cobaya` importing CLOE as an external likelihood\n",
    "**User-case**: *Run and go*. This is the most straightforward case where the user calls `Cobaya` to sample the posterior distribution of the parameters of interest. At the moment, this user-case runs one computation of the likelihood at one point in parameter space given the corresponding theoretical predictions of the Euclid observables.\n",
    "\n",
    "To run, Cobaya needs an 'input file'. Please read the comments in the cells below carefully to understand how this input file looks like and which options are available to be modified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import external loglike from CLOE; that is, the class EuclidLikelihood within cobaya_interface.py\n",
    "\n",
    "from cloe.cobaya_interface import EuclidLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us consider EuclidLikelihood as an external likelihood class for Cobaya.\n",
    "# Cobaya needs a dictionary or yaml file as input to start running.\n",
    "# This dictionary below ('info') can be modified by the user according to their needs.\n",
    "# The options that the user can modify are highlighted with the acronym (UC).\n",
    "\n",
    "info = {\n",
    "    #'params': Cobaya-protected key\n",
    "    # Includes the parameters that the user wants to sample over.\n",
    "'params': {\n",
    "        # (UC): each parameter below (which is a 'key' of another sub-dictionary)\n",
    "        # can contain a dictionary with the key 'prior', 'latex', ...\n",
    "        # If the prior dictionary is not passed to a parameter, this parameter is fixed.\n",
    "        # In this example, we are sampling the spectral index parameter ns.\n",
    "        # For more information, see Cobaya's quickstart example: https://cobaya.readthedocs.io/en/latest/example.html\n",
    "        'ombh2': 0.022445, #Reduced baryon density parameter\n",
    "        'omch2': 0.1205579307, #Reduced CDM density parameter\n",
    "        'H0': 67.0, #Hubble constant in km/s/Mpc\n",
    "        'tau': 0.0925, #Optical depth\n",
    "        'mnu': 0.06, #Sum of neutrino masses in eV\n",
    "        'nnu': 3.046, #Effective number of neutrinos\n",
    "        'As': 2.12605e-9, #Amplitude of the primordial scalar power spectrum\n",
    "        'ns': {'prior':{'min':0.8, 'max':1.2}}, #Spectral index (uniform prior)\n",
    "        'w': -1.0, #Present-day dark energy equation of state in CPL model\n",
    "        'wa': 0.0, #Derivative of dark energy equation of state in CPL model\n",
    "        'omk': 0.0, #Curvature density parameter\n",
    "        'omegam': None, #Derived parameter: Matter density parameter\n",
    "        'omegab': None, #Derived parameter: Baryon density parameter\n",
    "        'omeganu': None, #Derived parameter: Neutrino density parameter\n",
    "        'omnuh2': None, #Derived parameter: Reduced neutrino density parameter\n",
    "        'omegac': None, #Derived parameter: CDM density parameter\n",
    "        'N_eff': None},\n",
    "    #'theory': Cobaya-protected key\n",
    "    # Cobaya needs to ask some minimum theoretical requirements to a Boltzman solver\n",
    "    # (UC): Choose between CAMB or CLASS for the Boltzmann solver.\n",
    "    # Here, we use CAMB and specify some CAMB arguments, such as\n",
    "    # the number of massive neutrinos and DE model.\n",
    "    #\n",
    "    # ATTENTION: If you have CAMB/CLASS already installed and\n",
    "    # you are not using the likelihood conda environment\n",
    "    # or option (2) in cell (3) (Cobaya modules), you can add an extra key called 'path' within the camb dictionary\n",
    "    # to point to your already installed CAMB code\n",
    "    # NOTE: for values of the nonlinear flag larger than 0, a new key is added in info['theory']['camb']['extra_args'],\n",
    "    # i.e. 'halofit_version', which contains the requested version of Halofit/HMCODE, as described above\n",
    "    'theory': {'camb':\n",
    "               {'stop_at_error': True,\n",
    "                'extra_args':{'num_massive_neutrinos': 1,\n",
    "                              'dark_energy_model': 'ppf'}}},\n",
    "    #'sampler': Cobaya-protected key\n",
    "    # (UC): Choose the sampler.\n",
    "    # Check Cobaya's documentation to see the list of available samplers.\n",
    "    # For a full MCMC sampling, use the following line:\n",
    "    # 'sampler': {'mcmc': {'max_tries': 100000}},\n",
    "    # Here, use the 'evaluate' sampler to make a single likelihood computation.\n",
    "    'sampler': {'evaluate': None},\n",
    "    # 'packages_path': Cobaya-protected key\n",
    "    # This is the variable you need to update\n",
    "    # if you are running Cobaya with cobaya_modules (option (2) above).\n",
    "    # If you are using the conda likelihood environment or option (1),\n",
    "    # please, keep the line below commented\n",
    "    #\n",
    "    #'packages_path': modules_path,\n",
    "    #\n",
    "    #'output': Cobaya-protected key\n",
    "    # This is where the chains are stored.\n",
    "    # (UC): modify the path below within 'output' to choose a name and a directory for those files\n",
    "    'output': 'chains/my_euclid_experiment',\n",
    "    #'debug': Cobaya-protected key\n",
    "    # (UC): This specifies how much information to print, can be set to True/False.\n",
    "    'debug': False,\n",
    "    #'timing': Cobaya-protected key\n",
    "    # (UC): if timing: True, Cobaya returns how much time it took it to make a computation of the likelihood\n",
    "    # and how much time it takes each of the modules to perform their tasks\n",
    "    'timing': True,\n",
    "    #'force': Cobaya-protected key\n",
    "    # (UC): if 'force': True, Cobaya forces deleting the previous output files, if found, with the same name\n",
    "    'force': True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'likelihood': Cobaya-protected key\n",
    "# (UC): The user can select which data to use for the analysis.\n",
    "# Check Cobaya's documentation to see the list of the current available data experiments\n",
    "# In this DEMO, we load the EuclidLikelihood as an external function, and name it 'Euclid'\n",
    "info['likelihood'] = {'Euclid':\n",
    "                     {'external': EuclidLikelihood, # Likelihood Class to be read as external\n",
    "                     # Note: everything down below will overwrite the information read in the config folder\n",
    "                     #\n",
    "                     # Select which observables to use during the analysis by setting them to True or False\n",
    "                     'observables_selection': {\n",
    "                         'WL': {'WL': True, 'GCphot': True, 'GCspectro': False},\n",
    "                         'GCphot': {'GCphot': True, 'GCspectro': False},\n",
    "                         'GCspectro': {'GCspectro': True},\n",
    "                         'CG': {'CG': False},\n",
    "                         # Add RSD to photometric probes\n",
    "                         'add_phot_RSD': False,\n",
    "                         # Switch to allow for matrix transformations of theory and data vectors\n",
    "                         'matrix_transform_phot' : False # 'BNT' or 'BNT-test'\n",
    "                     },\n",
    "                     'use_magnification_bias_spectro': 0,\n",
    "                     'use_Weyl': False,\n",
    "                     # Plot the selected observables matrix\n",
    "                     'plot_observables_selection': True,\n",
    "                      # Nonlinear flags\n",
    "                      # NL_flag_phot_matter\n",
    "                        # 0 -> linear-only\n",
    "                        # 1 -> Halofit (Takahashi)\n",
    "                        # 2 -> Mead2016 (includes baryon corrections)\n",
    "                        # 3 -> Mead2020 (w/o baryon corrections)\n",
    "                        # 4 -> Euclid Emulator 2\n",
    "                        # 5 -> BACCO (matter)\n",
    "                     'NL_flag_phot_matter': 0,\n",
    "                      # NL_flag_spectro\n",
    "                        # 0 -> linear-only\n",
    "                        # 1 -> EFT\n",
    "                     'NL_flag_spectro': 0,\n",
    "                      # Baryonic feedback flag\n",
    "                      # With this, the user can specify which baryon model they want\n",
    "                      # For the time-being the available options are:\n",
    "                            #0 -> no baryonic feedback\n",
    "                            #1 -> Mead2016\n",
    "                            #2 -> Mead2020_feedback\n",
    "                            #3 -> BCemu\n",
    "                            #4 -> BACCO (baryonic feedback)\n",
    "                     'NL_flag_phot_baryon': 0,\n",
    "                     # NL_flag_phot_bias\n",
    "                        # 0 -> linear only\n",
    "                        # 1 -> Non-linear PT\n",
    "                     'NL_flag_phot_bias': 0,\n",
    "                     # IA_flag\n",
    "                        # 0 -> NLA\n",
    "                        # 1 -> TATT\n",
    "                     'IA_flag':1,\n",
    "                     # IR-resummation method\n",
    "                        # 'DST' -> Discrete sine transform\n",
    "                        # 'EH' -> Eisenstein-Hu                      \n",
    "                     'IR_resum': 'DST',\n",
    "                     # Use magnification bias for GC spectro\n",
    "                     'use_magnification_bias_spectro': 0,\n",
    "                      # Baryonic feedback z_dependence flag selector for\n",
    "                      # Bacco or BCemu emulators\n",
    "                         # False -> 1 set of parameters per redshift bin\n",
    "                         # True  -> Power law dependence on z\n",
    "                     'Baryon_redshift_model': False,\n",
    "                     'solver': 'camb',\n",
    "                     'params': {\n",
    "                                # (UC): galaxy bias parameters:\n",
    "                                # The bias parameters below are currently fixed to the\n",
    "                                # values used by the Inter Science Taskforce: Forecast (IST:F)\n",
    "                                # and presented in the corresponding IST:F paper (arXiv: 1910.09273).\n",
    "                                # However, they can be changed by the user and even sampled over by putting a prior.\n",
    "                                # Photometric galaxy bias parameters\n",
    "                                'b1_photo_bin1': 1.0997727037892875,\n",
    "                                'b1_photo_bin2': 1.220245876862528,\n",
    "                                'b1_photo_bin3': 1.2723993083933989,\n",
    "                                'b1_photo_bin4': 1.316624471897739,\n",
    "                                'b1_photo_bin5': 1.35812370570578,\n",
    "                                'b1_photo_bin6': 1.3998214171814918,\n",
    "                                'b1_photo_bin7': 1.4446452851824907,\n",
    "                                'b1_photo_bin8': 1.4964959071110084,\n",
    "                                'b1_photo_bin9': 1.5652475842498528,\n",
    "                                'b1_photo_bin10': 1.7429859437184225,\n",
    "                                # Magnification bias parameters\n",
    "                                'magnification_bias_1': 0.0,\n",
    "                                'magnification_bias_2': 0.0,\n",
    "                                'magnification_bias_3': 0.0,\n",
    "                                'magnification_bias_4': 0.0,\n",
    "                                'magnification_bias_5': 0.0,\n",
    "                                'magnification_bias_6': 0.0,\n",
    "                                'magnification_bias_7': 0.0,\n",
    "                                'magnification_bias_8': 0.0,\n",
    "                                'magnification_bias_9': 0.0,\n",
    "                                'magnification_bias_10': 0.0,\n",
    "                                # Shear calibration multiplicative bias parameters\n",
    "                                'multiplicative_bias_1': 0.0,\n",
    "                                'multiplicative_bias_2': 0.0,\n",
    "                                'multiplicative_bias_3': 0.0,\n",
    "                                'multiplicative_bias_4': 0.0,\n",
    "                                'multiplicative_bias_5': 0.0,\n",
    "                                'multiplicative_bias_6': 0.0,\n",
    "                                'multiplicative_bias_7': 0.0,\n",
    "                                'multiplicative_bias_8': 0.0,\n",
    "                                'multiplicative_bias_9': 0.0,\n",
    "                                'multiplicative_bias_10': 0.0,\n",
    "                                # Intrinsic alignment parameters\n",
    "                                'a1_ia': 1.72,\n",
    "                                'a2_ia': 2,\n",
    "                                'b1_ia': 1,\n",
    "                                'eta1_ia': -0.41,\n",
    "                                'eta2_ia': 1,\n",
    "                                'beta1_ia': 0.0,\n",
    "                                # Redshift distribution nuisance parameters: shifts\n",
    "                                'dz_1_GCphot': 0.0, 'dz_1_WL': 0.0,\n",
    "                                'dz_2_GCphot': 0.0, 'dz_2_WL': 0.0,\n",
    "                                'dz_3_GCphot': 0.0, 'dz_3_WL': 0.0,\n",
    "                                'dz_4_GCphot': 0.0, 'dz_4_WL': 0.0,\n",
    "                                'dz_5_GCphot': 0.0, 'dz_5_WL': 0.0,\n",
    "                                'dz_6_GCphot': 0.0, 'dz_6_WL': 0.0,\n",
    "                                'dz_7_GCphot': 0.0, 'dz_7_WL': 0.0,\n",
    "                                'dz_8_GCphot': 0.0, 'dz_8_WL': 0.0,\n",
    "                                'dz_9_GCphot': 0.0, 'dz_9_WL': 0.0,\n",
    "                                'dz_10_GCphot': 0.0, 'dz_10_WL': 0.0,\n",
    "                                'gamma_MG': 0.55,\n",
    "                                'sigma_z': 0.002,\n",
    "                                 # Spectroscopic galaxy bias parameters\n",
    "                                'b1_spectro_bin1': 1.441,\n",
    "                                'b1_spectro_bin2': 1.643,\n",
    "                                'b1_spectro_bin3': 1.862,\n",
    "                                'b1_spectro_bin4': 2.078,\n",
    "                                #Spectroscopic magnification bias\n",
    "                                'magnification_bias_spectro_bin1': 0.79,\n",
    "                                'magnification_bias_spectro_bin2': 0.87,\n",
    "                                'magnification_bias_spectro_bin3': 0.96,\n",
    "                                'magnification_bias_spectro_bin4': 0.98,},\n",
    "                     # k values for extrapolation of the matter power spectrum and k-array size\n",
    "                     'k_max_extrap': 500.0,\n",
    "                     'k_min_extrap': 1E-5,\n",
    "                     'k_samp': 1000,\n",
    "                     # z limit values and z-array size\n",
    "                     'z_min': 0.0,\n",
    "                     'z_max': 4.0,\n",
    "                     'z_samp': 100,\n",
    "                     # Use MG gamma\n",
    "                     'use_gamma_MG': False,\n",
    "                     # Use Weyl bypass\n",
    "                     'use_Weyl':False,\n",
    "                     # Use redshift-dependent purity for GCspectro or not\n",
    "                     'f_out_z_dep': False,\n",
    "                     # Add spectroscopic redshift errors\n",
    "                     'GCsp_z_err' : True,\n",
    "                     # Print theory predictions\n",
    "                     'print_theory' : False,\n",
    "                     #'data': This gives specifications for the paths of the input data files\n",
    "                     'data': {\n",
    "                        #'sample' specifies the first folder below the main data folder\n",
    "                        'sample': 'ExternalBenchmark',\n",
    "                        #'spectro' and 'photo' specify paths to data files.\n",
    "                        'spectro': {\n",
    "                            # GC Spectro root name should contain z{:s} string\n",
    "                            # to enable iteration over bins\n",
    "                            'root': 'cov_power_galaxies_dk0p004_z{:s}.fits',\n",
    "                            'redshifts': [\"1.\", \"1.2\", \"1.4\", \"1.65\"],\n",
    "                            'edges': [0.9, 1.1, 1.3, 1.5, 1.8],\n",
    "                            'scale_cuts_fourier': 'GCspectro-FourierSpace.yaml',\n",
    "                            'root_mixing_matrix': 'mm_FS230degCircle_m3_nosm_obsz_z0.9-1.1.fits',\n",
    "                            'Fourier': True},\n",
    "                        'photo': {\n",
    "                          'photo_data': 'standard',\n",
    "                            'redshifts': [0.2095, 0.489, 0.619, 0.7335, 0.8445, 0.9595, 1.087, 1.2395, 1.45, 2.038],\n",
    "                            'ndens_GC': 'niTab-EP10-RB00.dat',\n",
    "                            'ndens_WL': 'niTab-EP10-RB00.dat',\n",
    "                            'luminosity_ratio': 'luminosity_ratio.dat',\n",
    "                            # Photometric root names should contain z{:s} string\n",
    "                            # to specify IA model\n",
    "                            'root_GC': 'Cls_{:s}_PosPos.dat',\n",
    "                            'root_WL': 'Cls_{:s}_ShearShear.dat',\n",
    "                            'root_XC': 'Cls_{:s}_PosShear.dat',\n",
    "                            'root_mixing_matrix': 'fs2_mms_10zbins_32ellbins.fits',\n",
    "                            'IA_model': 'zNLA',\n",
    "                            # Photometric covariances root names should contain z{:s} string\n",
    "                            # to specify how the covariance was calculated\n",
    "                            'cov_GC': 'CovMat-PosPos-{:s}-20Bins.npz',\n",
    "                            'cov_WL': 'CovMat-ShearShear-{:s}-20Bins.npz',\n",
    "                            'cov_3x2pt': 'CovMat-3x2pt-{:s}-20Bins.npz',\n",
    "                            'cov_model': 'Gauss',  # or 'BNT-Gauss' if BNT selected above\n",
    "                            'Fourier': True\n",
    "                            }},\n",
    "                    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the yaml file corresponding to the Likelihood Parameters\n",
    "Cobaya needs to know which parameters the likelihood `EuclidLikelihood` expects (for example, nuisance parameters), apart from the cosmological parameters (i.e: $\\Omega_b$, $H_0$, $n_s$...) which are already known by the theory code (CAMB/CLASS). \n",
    "\n",
    "For that, a `yaml` file is generated instead of having those likelihood parameters hard-coded within `cobaya_interface.py`. To generate this `yaml` file, execute either the next cell or the next-to-next cell.\n",
    "\n",
    "Please be aware that this function will only make Cobaya expect those likelihood parameters. To set some fixed values or put a prior on them, the user needs to do so within the `info` python dictionary above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloe.auxiliary.likelihood_yaml_handler import set_halofit_version\n",
    "# Set the correct halofit version under the 'extra_args' field in ['theory']['camb']\n",
    "set_halofit_version(info, info['likelihood']['Euclid']['NL_flag_phot_matter'],\n",
    "                          info['likelihood']['Euclid']['NL_flag_phot_baryon'])\n",
    "# Now we are ready to run Cobaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way from using a hardcoded Cobaya info dictionary is loading the Cobaya configuration from a yaml file.\n",
    "# Run this cell only if you want to load the info dictionary from file.\n",
    "run_this_cell = False\n",
    "# WARNING: running this cell will overload the info dictionary defined in the previous cells\n",
    "\n",
    "from cloe.auxiliary.likelihood_yaml_handler import get_default_configs_path\n",
    "from cloe.auxiliary.likelihood_yaml_handler import update_cobaya_params_from_model_yaml\n",
    "from cloe.auxiliary.likelihood_yaml_handler import update_cobaya_dict_with_halofit_version\n",
    "from cloe.auxiliary.yaml_handler import yaml_read\n",
    "\n",
    "if run_this_cell:\n",
    "    # A test configuration yaml file is in 'configs/config_test.yaml'\n",
    "    # We can play with this file, or use another config file ...\n",
    "    config_test_path = get_default_configs_path() / 'config_test.yaml'\n",
    "    # Loading the dictionary from the file\n",
    "    config_test_dict = yaml_read(config_test_path)\n",
    "    info = config_test_dict['Cobaya']\n",
    "    # And read the model file name (only for this case, 'params' value is a file name where the model is specified)\n",
    "    # We can play with this model file, or use another model file ...\n",
    "    model_file = info['params']\n",
    "    # Joining the complete path for the model file\n",
    "    model_path = config_test_path.parent.joinpath(model_file)\n",
    "    # Updating the Cobaya info dictionary from the model\n",
    "    # i.e. writing the whole 'params' dict instead of the model file name\n",
    "    update_cobaya_params_from_model_yaml(info, model_path)\n",
    "    # Updating the Cobaya dictionary to add the halofit version corresponding to the selected NL flag\n",
    "    update_cobaya_dict_with_halofit_version(info)\n",
    "    set_halofit_version(info, info['likelihood']['Euclid']['NL_flag_phot_matter'],\n",
    "                              info['likelihood']['Euclid']['NL_flag_phot_baryon'])\n",
    "\n",
    "\n",
    "# Now we are ready to run Cobaya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cobaya run function\n",
    "from cobaya.run import run\n",
    "#import matplotlib\n",
    "#matplotlib.rcParams['text.usetex'] = False\n",
    "\n",
    "# Let's run Cobaya\n",
    "# the function run returns\n",
    "# info_updated: an information dictionary updated with the defaults,\n",
    "# equivalent to the updated yaml file produced by the shell invocation\n",
    "# samples: a sampler object, with a sampler.products()\n",
    "# being a dictionary of results.\n",
    "# For the mcmc sampler, the dictionary contains only one chain under the key sample.\n",
    "info_updated, samples = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the printed output by Cobaya**: \n",
    "- output: it tells details about the output\n",
    "- Prior: it shows the values sampled by the prior. In this case, our parameters of interest are all fixed so Cobaya reminds that.\n",
    "- CAMB: it calls the theory code you wanted to use (CAMB/CLASS, in this case, CAMB, and where it is installed).\n",
    "\n",
    "You see these outputs repeated twice because `CLOE` calls `Cobaya` internally twice, within the EuclidLikelihood, to calculate the fiducial cosmology.\n",
    "- evaluate: the 'evaluate' sampler gets initialized, looks for a point and evaluates the posterior.\n",
    "\n",
    "Note that since the option timing is True in the info dictionary, Cobaya tells you how much time it took to run CAMB and compute the likelihood (CLOE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Run `Cobaya model` with CLOE as external likelihood \n",
    "\n",
    "**User-case**: the analysis tool `Cobaya` has a wrapper of its `evaluate` sampler (the one executed in CASE 1), called `model`, that allows us to:\n",
    "\n",
    "* make an evaluation in a single point of prior, likelihood, and posterior distributions\n",
    "* retrieve derived parameters and other quantities\n",
    "\n",
    "The `model` wrapper is useful for debugging as well (i.e. imagine you are performing an MCMC sampling to find the best-fit values of a given model, and the MCMC chains get stuck for unknown reasons). With the `model`, you can investigate what is going on internally in `Cobaya` at each step of the sampling algorithm.\n",
    "\n",
    "Moreover, our EuclidLikelihood code, which is designed to work as an external likelihood code for `Cobaya` relies on this `model` wrapper to make the connection between `Cobaya`, the likelihood calculation, and the computation of the theoretical predictions (see **CASE 2.1** for further information).\n",
    "\n",
    "In this **CASE 2**, we will see how to activate the `model` wrapper, how to use it and how to understand the output it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: import model wrapper of Cobaya\n",
    "from cobaya.model import get_model\n",
    "\n",
    "# The `get_model` function of Cobaya imported in the line above needs a yaml or dictionary as an argument\n",
    "# exactly the same as the function `run` in cell 9 also needs.\n",
    "#\n",
    "# We measure the time to give us an estimation of how long it takes to initialize the likelihood\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Second: create an instance of the `model` wrapper called model\n",
    "model = get_model(info)\n",
    "print('Time for initialization of the likelihood: ', time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the printed output by Cobaya**: \n",
    "\n",
    "- Model: it tells you Cobaya is using the `model` wrapper, and it's reading the info dictionary.\n",
    "- Prior: it shows the values sampled by the prior. In this case, our parameters of interest are all fixed so Cobaya reminds that.\n",
    "- CAMB: it calls the theory code you wanted to use (CAMB/CLASS, in this case, CAMB, and where it is installed).\n",
    "\n",
    "You see these outputs repeated twice because CLOE calls Cobaya internally twice, within EuclidLikelihood, to calculate the fiducial cosmology.\n",
    "\n",
    "It takes around 10 seconds to initialize the likelihood (reading OU-LE3 data and computing fiducial cosmology). Note this is only performed once in a Monte Carlo run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalities of the `model` wrapper:\n",
    "As mentioned above, we can get an insight of what `Cobaya` is doing using the `model` object. We can ask, for instance:\n",
    " * (1) which quantities were **required** by the likelihood code and asked to the Boltzman solver through `Cobaya`\n",
    " * (2) at which values (i.e. redshift, scales...) those requirements were **requested**.\n",
    " \n",
    "To see how to ask for these quantities, execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Requirements needed by the likelihood code.\n",
    "# That means, which quantities are we asking to the Boltzman (CAMB/CLASS) through Cobaya?\n",
    "print('\\n Requirements \\n')\n",
    "print(model.provider.requirement_providers)\n",
    "# (2) At which values have the requirements been requested (redshift, scales...)?\n",
    "print('\\n Requested \\n')\n",
    "print(model.requested())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.provider.requirement_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (3) With the `model` wrapper you can also make an evaluation of the prior, likelihood, and posterior distributions\n",
    "\n",
    "ATTENTION: we initialized the `model` wrapper by reading the `info` dictionary above. This `info` dictionary has almost all the parameters of interest fixed (the only sampled parameters is $n_s$). Therefore, to make an evaluation of the probability distributions (priors, likelihoods, and posterior), you need:\n",
    "\n",
    "* First: get a point of the sampled parameters from the prior distribution \n",
    "* Second: pass this point to the logposterior method\n",
    "\n",
    "See comments in the cell below to understand how to retrieve the values of these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the moment, we are sampling only ns\n",
    "# If there are sampled parameters, we need first to obtain a value from the prior\n",
    "# i.e: (FIRST)\n",
    "point = dict(zip(model.parameterization.sampled_params(),\n",
    "                 model.prior.sample(ignore_external=True)[0]))\n",
    "t1 = time.time()\n",
    "# (3) Make a computation of the logposterior on that point\n",
    "logposterior = model.logposterior(point)\n",
    "# If there were no sampled parameters, you can simply execute\n",
    "#logposterior = model.logposterior({})\n",
    "t2 = time.time()\n",
    "\n",
    "# Note that we are measuring the time for illustration purposes only.\n",
    "\n",
    "print('Time to compute the logposterior: ', t2-t1)\n",
    "print('Full log-posterior:')\n",
    "print('   logposterior: %g' % logposterior.logpost)\n",
    "print('   logpriors: %r' % dict(zip(list(model.prior), logposterior.logpriors)))\n",
    "print('   loglikelihoods: %r' % dict(zip(list(model.likelihood), logposterior.loglikes)))\n",
    "print('   derived params: %r' % dict(zip(list(model.parameterization.derived_params()), logposterior.derived)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2.1: EuclidLikelihood package\n",
    "\n",
    "**User-case**: this case allows the user to go one level deeper down into the `CLOE` code, so that the user can retrieve and plot:\n",
    "\n",
    "* Benchmark data used as mock data during the calculation of the likelihood. For instance:\n",
    "    * $n(z)$: galaxy density distributions\n",
    "* Cosmological quantities provided by the Boltzman solver through Cobaya. For example:\n",
    "    * $H(z)$: Hubble factor\n",
    "    * $r(z)$, $D_A$: comoving and angular diameter distances\n",
    "    * $\\sigma_8$, $f\\sigma_8$: amplitude of the (linear) power spectrum on scales of 8 $h^{-1}$ Mpc and its product with the growth rate\n",
    "* Internal cosmological quantities computed by the EuclidLikelihood package itself:\n",
    "    * $D(z)$, $f(z)$: growth factor and growth rate\n",
    "    * $P_{\\delta\\delta}, P_{gg}, P_{g\\delta}, P_{\\delta i}, P_{gi}, P_{ii}$: matter power spectrum obtained by the Boltzman solver in Cobaya and different power spectra in CLOE\n",
    "* Theoretical predictions of the photometric and spectroscopic observables\n",
    "    * $W_i^{\\rm GC}(z), W_i^{\\rm \\gamma}(z), W_i^{\\rm IA}(z), W_i^{\\rm RSD}(z), W_i^{\\rm mag}(z)$ : window functions or kernel for galaxy clustering (GC), shear ($\\gamma$), intrinsic alignments (IA), redshift space distortions (RSD), and magnification bias (mag).\n",
    "    * $C_\\ell$: angular power spectra\n",
    "    * $P_\\ell$: Legendre multipole power spectra\n",
    "* computation of the $\\chi^2$\n",
    "\n",
    "To be able to access all of these quantities and get a grasp of what EuclidLikelihood actually does, **you need to have loaded an instance of the `model` wrapper of Cobaya (explained in CASE 2)**. In reality, what we are doing in this **CASE 2.1** is to reproduce the steps that are done internally by `Cobaya` at each step of the sampling procedure within the file `cobaya_interface.py` of the likelihood package. Therefore, understanding **CASE 2.1** will also help the user to understand the details of the EuclidLikelihood source code and structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class EuclidLikelihood\n",
    "like = EuclidLikelihood()\n",
    "\n",
    "# Initialize default parameters for redshift, k-array, fiducial cosmology, ...\n",
    "like.initialize()\n",
    "\n",
    "# Get the cosmo_dictionary where all the cosmology + theory parameters are saved\n",
    "# ATTENTION: as explained above, you need to pass the `cobaya wrapper model` initialized\n",
    "# in CASE 2 as an argument of the function, as well as the parameters of your theory.\n",
    "# In CASE 1, when only Cobaya run is used, it internally creates this `model` instance itself\n",
    "like.passing_requirements(model, info, **model.provider.params)\n",
    "\n",
    "# Update the cosmology dictionary with interpolators + basic quantities such as\n",
    "# P_gg, P_delta...\n",
    "like.cosmo.update_cosmo_dic(like.cosmo.cosmo_dic['z_win'], 0.05)\n",
    "\n",
    "# Show what the cosmo_dic actually contains\n",
    "print('\\nKeys of the cosmo_dic: \\n', list(like.cosmo.cosmo_dic.keys()))\n",
    "print('\\nKeys of the nuisance params within cosmo_dic: \\n', list(like.cosmo.cosmo_dic['nuisance_parameters'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also access the quantities of the Euclike module as follows:\n",
    "# This function will return the loglike\n",
    "loglike = like.likefinal.loglike(like.cosmo.cosmo_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the computation of the chi2, you can access the following quantities of the Euclike module\n",
    "print('\\nList of attributes of the euclike object: \\n', list(vars(like.likefinal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can print, for instance, the data read by CLOE\n",
    "print(like.likefinal.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot internal quantities and cosmological observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "\n",
    "plt.rc('xtick',labelsize=20)\n",
    "plt.rc('ytick',labelsize=20)\n",
    "plt.rc('font',size=20)\n",
    "plt.rc('axes', titlesize=25)\n",
    "plt.rc('axes', labelsize=20)\n",
    "plt.rc('lines', linewidth=3)\n",
    "plt.rc('lines', markersize=6)\n",
    "plt.rc('legend', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the background quantities of cosmo_dic\n",
    "# See http://pf-ist-likelihood.pages.euclid-sgs.uk/likelihood-implementation/likelihood.cosmo.cosmology.html\n",
    "# for extra information\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(13,10))\n",
    "for ax in axs.flatten():\n",
    "    ax.tick_params(axis='both',which='both',direction='in')\n",
    "fig.suptitle('Background quantities')\n",
    "axs[0, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['H_z_func'](like.cosmo.cosmo_dic['z_win']))\n",
    "axs[0, 0].set_xlabel(r'$z$')\n",
    "axs[0, 0].set_ylabel(r'$H(z)$ $[\\rm km \\times s^{-1} Mpc^{-1}]$')\n",
    "axs[0, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['d_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              label = r'$D_{\\rm{A}}(z)$ $[\\rm{Mpc}]$')\n",
    "axs[0, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['r_z_func'](like.cosmo.cosmo_dic['z_win']), '--',\n",
    "              label = r'$r(z)$')\n",
    "axs[0, 1].set_xlabel(r'$z$')\n",
    "axs[0, 1].legend(frameon=False)\n",
    "axs[1, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['sigma8_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              label = r'$\\sigma_8(z)$')\n",
    "axs[1, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['fsigma8_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              '--', label = r'$f\\sigma_8(z)$')\n",
    "axs[1, 0].set_xlabel(r'$z$')\n",
    "axs[1, 0].legend(frameon=False)\n",
    "axs[1, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['D_z_k'],\n",
    "              label = r'$D(z)$')\n",
    "axs[1, 1].plot(like.cosmo.cosmo_dic['z_win'],\n",
    "               like.cosmo.cosmo_dic['f_z'](like.cosmo.cosmo_dic['z_win']),\n",
    "              '--', label = r'$f(z) = f\\sigma_8/\\sigma_8$')\n",
    "axs[1, 1].set_xlabel(r'$z$')\n",
    "axs[1, 1].legend(frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.90)\n",
    "if save_plots:\n",
    "    plt.savefig('figs/background_quantities.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the matter power spectrum and other spectra quantities\n",
    "# 'Pgg_spectro', 'Pgg_phot', 'Pgdelta_phot', 'Pgdelta_spectro', 'Pii', 'Pdeltai', 'Pgi_phot', 'Pgi_spectro'\n",
    "# See http://pf-ist-likelihood.pages.euclid-sgs.uk/likelihood-implementation/likelihood.cosmo.cosmology.html\n",
    "# for extra information\n",
    "\n",
    "k_label           = r'$k$ $[\\rm{Mpc}^{-1}]$'\n",
    "pm_label          = r'$P_{\\delta\\delta} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgg_spectro_label = r'$P_{\\rm{gg}}^{\\,\\rm{spectro}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgg_phot_label    = r'$P_{\\rm{gg}}^{\\,\\rm{phot}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgd_spectro_label = r'$P_{\\rm{g}\\delta}^{\\,\\rm{spectro}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgd_phot_label    = r'$P_{\\rm{g}\\delta}^{\\,\\rm{phot}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pII_label         = r'$P_{\\,\\rm{II}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pdI_label         = r'$P_{\\delta\\rm{I}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgI_phot_label    = r'$P_{\\rm{gI}}^{\\,\\rm{phot}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "pgI_spectro_label = r'$P_{\\rm{gI}}^{\\,\\rm{spectro}} \\left[\\rm{Mpc}^3\\right]$'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fig, axs = plt.subplots(9, 2, figsize=(13,47))\n",
    "for ax in axs.flatten():\n",
    "    ax.tick_params(axis='both',which='both',direction='in')\n",
    "fig.suptitle('Spectra')\n",
    "ks=np.logspace(-5, 0, 100)\n",
    "axs[0, 0].loglog(ks, like.cosmo.cosmo_dic['Pk_delta'].P(like.cosmo.cosmo_dic['z_win'][0], ks), 'k-',\n",
    "           label=r\"$z = {:.2f}$\".format(like.cosmo.cosmo_dic['z_win'][0]))\n",
    "axs[0, 0].set_xlabel(k_label)\n",
    "axs[0, 0].set_ylabel(pm_label)\n",
    "axs[0, 0].legend(frameon=False)\n",
    "#------\n",
    "axs[0, 1].loglog(ks, like.cosmo.cosmo_dic['Pk_delta'].P(like.cosmo.cosmo_dic['z_win'][-1], ks), 'k-',\n",
    "           label=r\"$z = {:.2f}$\".format(like.cosmo.cosmo_dic['z_win'][-1]))\n",
    "axs[0, 1].set_xlabel(k_label)\n",
    "axs[0, 1].set_ylabel(pm_label)\n",
    "axs[0, 1].legend(frameon=False)\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[1, 0].loglog(k, like.cosmo.cosmo_dic['Pgg_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][25], k, 1), 'o', color=sns.color_palette(\"Paired\")[0],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][25]) if i == 0 else \"\")\n",
    "    axs[1, 1].loglog(k, like.cosmo.cosmo_dic['Pgg_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][35], k, 1), 'o', color=sns.color_palette(\"Paired\")[0],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][35]) if i == 0 else \"\")\n",
    "axs[1, 0].set_xlabel(k_label)\n",
    "axs[1, 0].set_ylabel(pgg_spectro_label)\n",
    "axs[1, 1].set_xlabel(k_label)\n",
    "axs[1, 1].set_ylabel(pgg_spectro_label)\n",
    "axs[1, 0].legend(frameon=False)\n",
    "axs[1, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[2, 0].loglog(k, like.cosmo.cosmo_dic['Pgg_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[1],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[2, 1].loglog(k, like.cosmo.cosmo_dic['Pgg_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[1],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[2, 0].set_xlabel(k_label)\n",
    "axs[2, 0].set_ylabel(pgg_phot_label)\n",
    "axs[2, 1].set_xlabel(k_label)\n",
    "axs[2, 1].set_ylabel(pgg_phot_label)\n",
    "axs[2, 0].legend(frameon=False)\n",
    "axs[2, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[3, 0].loglog(k, like.cosmo.cosmo_dic['Pgdelta_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][25], k, 1), 'o', color=sns.color_palette(\"Paired\")[2],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][25]) if i == 0 else \"\")\n",
    "    axs[3, 1].loglog(k, like.cosmo.cosmo_dic['Pgdelta_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][35], k, 1), 'o', color=sns.color_palette(\"Paired\")[2],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][35]) if i == 0 else \"\")\n",
    "axs[3, 0].set_xlabel(k_label)\n",
    "axs[3, 0].set_ylabel(pgd_spectro_label)\n",
    "axs[3, 1].set_xlabel(k_label)\n",
    "axs[3, 1].set_ylabel(pgd_spectro_label)\n",
    "axs[3, 0].legend(frameon=False)\n",
    "axs[3, 1].legend(frameon=False)\n",
    "\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[4, 0].loglog(k, like.cosmo.cosmo_dic['Pgdelta_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[3],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[4, 1].loglog(k, like.cosmo.cosmo_dic['Pgdelta_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[3],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[4, 0].set_xlabel(k_label)\n",
    "axs[4, 0].set_ylabel(pgd_phot_label)\n",
    "axs[4, 1].set_xlabel(k_label)\n",
    "axs[4, 1].set_ylabel(pgd_phot_label)\n",
    "axs[4, 0].legend(frameon=False)\n",
    "axs[4, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[5, 0].loglog(k, like.cosmo.cosmo_dic['Pii'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[4],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[5, 1].loglog(k, like.cosmo.cosmo_dic['Pii'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[4],\n",
    "                     label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[5, 0].set_xlabel(k_label)\n",
    "axs[5, 0].set_ylabel(pII_label)\n",
    "axs[5, 1].set_xlabel(k_label)\n",
    "axs[5, 1].set_ylabel(pII_label)\n",
    "axs[5, 0].legend(frameon=False)\n",
    "axs[5, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[6, 0].semilogx(k, like.cosmo.cosmo_dic['Pdeltai'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[5],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[6, 1].semilogx(k, like.cosmo.cosmo_dic['Pdeltai'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[5],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[6, 0].set_xlabel(k_label)\n",
    "axs[6, 0].set_ylabel(pdI_label)\n",
    "axs[6, 1].set_xlabel(k_label)\n",
    "axs[6, 1].set_ylabel(pdI_label)\n",
    "axs[6, 0].legend(frameon=False, loc=3)\n",
    "axs[6, 1].legend(frameon=False, loc=3)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[7, 0].semilogx(k, like.cosmo.cosmo_dic['Pgi_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[6],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[7, 1].semilogx(k, like.cosmo.cosmo_dic['Pgi_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[6],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[7, 0].set_xlabel(k_label)\n",
    "axs[7, 0].set_ylabel(pgI_phot_label)\n",
    "axs[7, 1].set_xlabel(k_label)\n",
    "axs[7, 1].set_ylabel(pgI_phot_label)\n",
    "axs[7, 0].legend(frameon=False, loc=3)\n",
    "axs[7, 1].legend(frameon=False, loc=3)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[8, 0].semilogx(k, like.cosmo.cosmo_dic['Pgi_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'o', color=sns.color_palette(\"Paired\")[7],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[8, 1].semilogx(k, like.cosmo.cosmo_dic['Pgi_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'o', color=sns.color_palette(\"Paired\")[7],\n",
    "                       label=r\"$z = {:.2f}$\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[8, 0].set_xlabel(k_label)\n",
    "axs[8, 0].set_ylabel(pgI_spectro_label)\n",
    "axs[8, 1].set_xlabel(k_label)\n",
    "axs[8, 1].set_ylabel(pgI_spectro_label)\n",
    "axs[8, 0].legend(frameon=False, loc=3)\n",
    "axs[8, 1].legend(frameon=False, loc=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.97)\n",
    "if save_plots:\n",
    "    plt.savefig('figs/power_spectra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the initial data read by the like_calc module (class Euclike).\n",
    "# This data is at the moment the fiducial data stored within the data folder of the repository\n",
    "\n",
    "# i.e: let's plot the galaxy distributions for GCphot and WL (at the moment, they are the same)\n",
    "zs = np.linspace(0, 4, 1000)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10,10))\n",
    "i = 0\n",
    "j = 0\n",
    "for ax in axs.flatten():\n",
    "    ax.tick_params(axis='both',which='both',direction='in')\n",
    "for key, value in like.likefinal.data_ins.nz_dict_WL.items():\n",
    "    axs[0].plot(zs, value(zs), label = '$n_{{{}}}$'.format(i+1), linewidth=2, color=sns.color_palette(\"mako\", 10)[i])\n",
    "    i=i+1\n",
    "for key, value in like.likefinal.data_ins.nz_dict_GC_Phot.items():\n",
    "    axs[1].plot(zs, value(zs), label = '$n_{{{}}}$'.format(j+1), linewidth=2, color=sns.color_palette(\"rocket\", 10)[j])\n",
    "    j=j+1\n",
    "axs[0].set_xlabel(r'$z$')\n",
    "axs[0].set_ylabel(r'$n(z)$ $\\left[\\rm{sr}^{-1}\\right]$')\n",
    "axs[0].set_title(r'$\\rm WL$')\n",
    "axs[0].legend(frameon=False, ncol=2)\n",
    "axs[1].set_xlabel(r'$z$')\n",
    "axs[1].set_ylabel(r'$n(z)$ $\\left[\\rm{sr}^{-1}\\right]$')\n",
    "axs[1].set_title(r'$\\rm GCphot$')\n",
    "axs[1].legend(frameon=False, ncol=2);\n",
    "plt.tight_layout()\n",
    "if save_plots:\n",
    "    plt.savefig('figs/n_z.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the window functions for the photometric observables\n",
    "# For that, you need to import the photo class and read the cosmology dictionary and the n(z) distributions above\n",
    "from cloe.photometric_survey.photo import Photo\n",
    "photo = Photo(like.cosmo.cosmo_dic, like.likefinal.data_ins.nz_dict_WL, like.likefinal.data_ins.nz_dict_GC_Phot, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "color = list(mcolors.TABLEAU_COLORS.values())\n",
    "fig, axs = plt.subplots(5, 1, figsize=(13,20))\n",
    "for ax in axs.flatten():\n",
    "    ax.tick_params(axis='both',which='both',direction='in')\n",
    "for i in range(0, 10):\n",
    "    axs[0].plot(zs, photo.WL_window(zs, i+1), '-', linewidth=2, color=sns.color_palette(\"mako\", 10)[i], label='$n_{{{}}}$'.format(i+1))\n",
    "    axs[1].plot(zs, photo.IA_window(zs, i+1), '-', linewidth=2, color=sns.color_palette(\"mako\", 10)[i], label='$n_{{{}}}$'.format(i+1))\n",
    "    axs[2].plot(zs, photo.GC_window(zs, i+1), '-', linewidth=2, color=sns.color_palette(\"rocket\", 10)[i], label='$n_{{{}}}$'.format(i+1))\n",
    "    axs[3].plot(zs, photo.magnification_window(zs, i+1), '-', linewidth=2, color=sns.color_palette(\"rocket\", 10)[i], label='$n_{{{}}}$'.format(i+1))\n",
    "    axs[4].plot(zs[3:], photo.GC_window_RSD(zs[3:], 40, i+1)[0][0], '-', linewidth=2, color=sns.color_palette(\"rocket\", 10)[i], label='$n_{{{}}}$'.format(i+1))\n",
    "\n",
    "axs[0].set_xlabel(r'$z$')\n",
    "axs[0].set_ylabel(r'$W_i^{\\gamma}$ $\\left[\\rm{Mpc}^{-1}\\right]$')\n",
    "axs[0].legend(frameon=False, ncol=2)\n",
    "axs[1].set_xlabel(r'$z$')\n",
    "axs[1].set_ylabel(r'$W_i^{\\rm{IA}}$ $\\left[\\rm{Mpc}^{-1}\\right]$')\n",
    "axs[1].legend(frameon=False, ncol=2)\n",
    "axs[2].set_xlabel(r'$z$')\n",
    "axs[2].set_ylabel(r'$W_i^{\\rm GCphot}$ $\\left[\\rm{Mpc}^{-1}\\right]$')\n",
    "axs[2].legend(frameon=False, ncol=2)\n",
    "axs[3].set_xlabel(r'$z$')\n",
    "axs[3].set_ylabel(r'$W_i^{\\rm mag}$ $\\left[\\rm{Mpc}^{-1}\\right]$')\n",
    "axs[3].legend(frameon=False, ncol=2)\n",
    "axs[4].set_xlabel(r'$z$')\n",
    "axs[4].set_ylabel(r'$W_i^{\\rm RSD}$ $\\left[\\rm{Mpc}^{-1}\\right]$')\n",
    "axs[4].legend(frameon=False, ncol=2)\n",
    "plt.tight_layout()\n",
    "if save_plots:\n",
    "    plt.savefig('figs/window_functions.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Euclid final observables\n",
    "\n",
    "We can use the auxiliary module of the CLOE to plot the final observables. **Have in mind that the predicted values for the angular power spectra will probably not agree with the fiducial plotted values from the Benchmark data as we are currently sampling $n_s$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the Plotter Class\n",
    "from cloe.auxiliary.plotter import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print if there is any sampled parameter\n",
    "for k in model.parameterization.sampled_params():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the photometric observables for these redshift bins\n",
    "bin_i = 1\n",
    "bin_j = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WL angular power spectrum\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.tick_params(axis='both',which='both',direction='in')\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        pl_label = 'ns'#'{}={:.4f}'.format(param, model.parameterization.sampled_params()[param])\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "pl_label = '$n_s = {:.2f}$'.format(model.parameterization.sampled_params()['ns'])\n",
    "pl_inst = Plotter(cosmo_dic=like.cosmo.cosmo_dic, data=like.likefinal.data)\n",
    "ax1 = pl_inst.plot_external_Cl_phot(bin_i, bin_j, ax1, probe='WL', pl_label='$\\\\rm Benchmark$')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), bin_i, bin_j, ax1, probe='WL', pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel('$C_{1,1}^{\\\\rm{WL}}(\\\\ell) \\\\left[\\\\rm{sr}\\\\right]$')\n",
    "ax1.set_xscale('linear')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend(fontsize=18);\n",
    "if save_plots:\n",
    "    plt.savefig('figs/C_l_WL.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCphot angular power spectrum\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.tick_params(axis='both',which='both',direction='in')\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "pl_label = '$n_s = {:.2f}$'.format(model.parameterization.sampled_params()['ns'])\n",
    "ax1 = pl_inst.plot_external_Cl_phot(bin_i, bin_j, ax1, probe='GC-Phot', pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), bin_i, bin_j, ax1, probe='GC-Phot', pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel('$C_{1,1}^{\\\\rm{GCphot}}(\\\\ell) \\\\left[\\\\rm{sr}\\\\right]$')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend(fontsize=18);\n",
    "if save_plots:\n",
    "    plt.savefig('figs/C_l_GCphot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation WL x GCphot angular power spectrum (GGL)\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.tick_params(axis='both',which='both',direction='in')\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "pl_label = '$n_s = {:.2f}$'.format(model.parameterization.sampled_params()['ns'])\n",
    "ax1 = pl_inst.plot_external_Cl_XC(bin_i, bin_j, ax1, pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_Cl_XC(np.logspace(1, 3.6, 10), bin_i, bin_j, ax1, pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel('$C_{1,1}^{\\\\rm{GGL}}(\\\\ell) \\\\left[\\\\rm{sr}\\\\right]$')\n",
    "ax1.set_xscale('log')\n",
    "#ax1.set_yscale('log')\n",
    "ax1.legend();\n",
    "if save_plots:\n",
    "    plt.savefig('figs/C_l_GGL.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the spectro observable: choose the multipole\n",
    "multipole = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCspectro observable\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.tick_params(axis='both',which='both',direction='in')\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "pl_label = '$n_s = {:.2f}$'.format(model.parameterization.sampled_params()['ns'])\n",
    "ax1 = pl_inst.plot_external_GC_spectro(\"1.2\", multipole, ax1, pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_GC_spectro_multipole(1.2, np.linspace(0.01, 0.5), multipole, ax1, pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$k$ $\\left[\\rm{Mpc}^{-1}\\right]$', fontsize=20)\n",
    "ax1.set_ylabel(r'$P_{}$ $\\left[\\rm Mpc^3 \\right]$'.format(multipole), fontsize=20)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend();\n",
    "if save_plots:\n",
    "    plt.savefig('figs/P_l_k.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

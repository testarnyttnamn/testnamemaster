{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO: CLOE\n",
    "\n",
    "**Description**: this DEMO allows to compute the Galaxy Clustering and Weak Lensing observational probes as defined in the current recipe and computes the likelihood value given some benchmark data. It uses `Cobaya` as the main Bayesian Analysis tool.\n",
    "\n",
    "It contains three potential different scenarios for the user (called user-cases) corresponding to CASE 1, 2 and 3 in the notebook. A basic description of each of the user-case is the following:\n",
    "\n",
    "* **CASE 1**: samples the posterior distribution of the parameters of interest (cosmological or nuisance parameters) by running `Cobaya` with the external Euclid Likelihood and the sampler of your choice within the list of samplers available in `Cobaya`. At the moment, this user case executes a single point evaluation of the likelihood using the `Cobaya` sampler `evaluate`.\n",
    "\n",
    "* **CASE 2**: creates a `model` of `Cobaya` using an internal wrapper of `Cobaya` itself. This wrapper is based on the sampler `evaluate` of `Cobaya`. The `model` allows you to make a single computation of the priors, likelihoods and posterior, measure the time needed by each module or retrieve the information of which theoretical quantities were asked to the Boltzman solvers, for instance. This `model` instance is important, because it is the way the connection between `Cobaya` and the `EuclidLikelihood` code is made internally within `cobaya_interface.py`. In fact, the `model` instance is essential if you want to run CASE 2.1.\n",
    "\n",
    "* **CASE 2.1**: the final section of the notebook retrieves and plots internal theoretical quantities computed by the CLOE code. Be aware that, to be able to retrieve and plot quantities, you need to run first **CASE 2**, because CASE 2.1 requires the `model` instance to be loaded. You can plot the following quantities:\n",
    "    * $H(z)$: Hubble factor\n",
    "    * $r(z)$, $D_A$: comoving and angular diameter distances\n",
    "    * $\\sigma_8$, $f\\sigma_8$: amplitude of the (linear) power spectrum on the scale of 8 $h^{-1} Mpc$, and the product of the growth rate, and the amplitude of the (linear) power spectrum on the scale of 8 $h^{-1} Mpc$\n",
    "    * $D(z)$, $f(z)$: growth factor and growth rate\n",
    "    * $P_m, P_{gg}, P_{g\\delta}, P_{\\delta i}, P_{gi}, P_{ii}$: matter power spectrum obtained by the Boltzman solver by `Cobaya` and different power spectra\n",
    "    * $n(z)$: galaxy density distributions\n",
    "    * $W_i^{GC}, W_i^{\\gamma}, W_i^{IA}$: window functions or kernel for Galaxy Clustering (GC), Shear ($\\gamma$) and Intrinsic Alignment.\n",
    "    * $C_\\ell$: angular power spectra\n",
    "    * $P_\\ell$: Legendre multiples\n",
    "\n",
    "\n",
    "**README**: https://gitlab.euclid-sgs.uk/pf-ist-likelihood/likelihood-implementation/-/blob/master/README.md\n",
    "\n",
    "**Install**: in order to use this DEMO notebook, you need to clone the repository `https://gitlab.euclid-sgs.uk/pf-ist-likelihood/likelihood-implementation.git`, and install the CLOE as described in the README.\n",
    "Alternatively you may be ready to run if ```Cobaya``` and ```CAMB/CLASS``` are installed. See details below. \n",
    "\n",
    "**Cobaya documentation**: https://cobaya.readthedocs.io/en/latest/\n",
    "\n",
    "**Python information**: if the user is not confortable with some python vocabulary used in this notebook,\n",
    "a nice python review can be found here\n",
    "https://wiki.python.org/moin/BeginnersGuide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General python imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have clone the repository and open this notebook,\n",
    "# this notebook should be in likelihood-implementation/notebooks\n",
    "# Let's set the working directory to be likelihood-implementation\n",
    "\n",
    "likelihood_path = os.path.realpath(os.path.join(os.getcwd(),'..'))\n",
    "sys.path.insert(0, likelihood_path)\n",
    "print('Setting as working directory: ', likelihood_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib params set-up\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "plt.rc('font',size=25)\n",
    "plt.rc('axes', titlesize=26)\n",
    "plt.rc('axes', labelsize=25)\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('lines', markersize=6)\n",
    "plt.rc('legend', fontsize=20)\n",
    "plt.rc('mathtext', fontset='stix')\n",
    "plt.rc('font', family='STIXGeneral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cobaya` needs some modules to run: i.e: CAMB, CLASS, Polychord, other likelihood codes, and data (Planck 18, DES...)\n",
    "If you have installed the CLOE as in the README instructions, you need to activate the conda environment `likelihood` to run. This conda environment has CAMB installed, so you won't need to worry about anything else\n",
    "\n",
    "Alternatively, if you have already installed Cobaya and other Cosmological codes such as CAMB, CLASS, Polychord, or Planck 18 you have 2 options:\n",
    "\n",
    "* **(1)**:  point out where each of them is installed with the flag 'path' in the dictionary of cell 5. See the comment in the cell 5 corresponding to the 'theory' key of the 'info' dictionary\n",
    "\n",
    "\n",
    "* **(2)**: if you installed the Cosmological codes as Cobaya automatic installation suggests  (https://cobaya.readthedocs.io/en/latest/installation_cosmo.html) you need to point out the path to your modules\n",
    "as in the variable `modules_path` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: write down the path to your COBAYA modules if you want to follow option (2) above.\n",
    "# Otherwise skip this cell\n",
    "# modules_path = \"/data2/cobaya_modules/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE 1: 'Run `Cobaya` with Euclid-Likelihood \n",
    "**User-case**: *Run and go*. This is the most straightforward case where the user calls `Cobaya` to sample the posterior distribution of the parameters of interest. At the moment, this user-case runs one computation of the likelihood on one point of the parameters space given some theoretical predictions of Euclid observables.\n",
    "\n",
    "To run, Cobaya needs an 'input file'. Please, read carefully the comments in the cells below to understand \n",
    "how this input file looks like and which options are available to be modified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import external loglike from the Likelihood Package within cobaya_interface.py\n",
    "\n",
    "from likelihood.cobaya_interface import EuclidLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We are running the Euclid-Likelihood as an external likelihood class for Cobaya\n",
    "# Cobaya needs a dictionary or yaml file as input to start running\n",
    "# This dictionary below ('info') can be modified up to some point by the user to\n",
    "# adapt it to the user's needs.\n",
    "# The options that can be modified by the user are pointed with the acronym (UC).\n",
    "\n",
    "info = {\n",
    "    #'params': Cobaya's protected key of the input dictionary. \n",
    "    # Includes the parameters that the user would like to sample over:\n",
    "'params': {\n",
    "        # (UC): each parameter below (which is a 'key' of another sub-dictionary) can contain a dictionary\n",
    "        # with the key 'prior', 'latex'...\n",
    "        # If the prior dictionary is not passed to a parameter, this parameter is fixed.\n",
    "        # In this example, we are sampling the parameter ns\n",
    "        #Â For more information see: https://cobaya.readthedocs.io/en/latest/example.html\n",
    "        'ombh2': 0.022445, #Omega density of baryons times the reduced Hubble parameter squared\n",
    "        'omch2': 0.1205579307, #Omega density of cold dark matter times the reduced Hubble parameter squared\n",
    "        'H0': 67, #Hubble parameter evaluated today (z=0) in km/s/Mpc\n",
    "        'tau': 0.0925, #optical depth\n",
    "        'mnu': 0.06, #  sum of the mass of neutrinos in eV\n",
    "        'nnu': 3.046, #N_eff of relativistic species \n",
    "        'As': 2.12605e-9, #Amplitude of the primordial scalar power spectrum\n",
    "        'ns': {'prior':{'min':0.8, 'max':1.2}}, # primordial power spectrum tilt (sampled with an uniform prior)\n",
    "        'w': -1, #Dark energy fluid model\n",
    "        'wa': 0, #Dark energy fluid model\n",
    "        'omk': 0.0, #curvature density\n",
    "        'omegam': None, #DERIVED parameter: Omega matter density\n",
    "        'omegab': None, #DERIVED parameter: Omega baryon density\n",
    "        'omeganu': None, #DERIVED parameter: Omega neutrino density\n",
    "        'omnuh2': None, #DERIVED parameter: Omega neutrino density times de reduced Hubble parameter squared\n",
    "        'omegac': None, #DERIVED parameter: Omega cold dark matter density\n",
    "        'N_eff': None,\n",
    "        # (UC): galaxy bias parameters:\n",
    "        # The bias parameters below are currently fixed to the\n",
    "        # values used by the Inter Science Taskforce: Forecast (IST:F)\n",
    "        # and presented in the corresponding IST:F paper (arXiv: 1910.09273).\n",
    "        # However, they can be changed by the user and even sample over them by putting a prior\n",
    "        # Photometric bias parameters\n",
    "        'b1_photo': 1.0997727037892875,\n",
    "        'b2_photo': 1.220245876862528,\n",
    "        'b3_photo': 1.2723993083933989,\n",
    "        'b4_photo': 1.316624471897739,\n",
    "        'b5_photo': 1.35812370570578,\n",
    "        'b6_photo': 1.3998214171814918,\n",
    "        'b7_photo': 1.4446452851824907,\n",
    "        'b8_photo': 1.4964959071110084,\n",
    "        'b9_photo': 1.5652475842498528,\n",
    "        'b10_photo': 1.7429859437184225,\n",
    "        # Spectroscopic bias parameters\n",
    "        'b1_spectro': 1.46,\n",
    "        'b2_spectro': 1.61,\n",
    "        'b3_spectro': 1.75,\n",
    "        'b4_spectro': 1.90,\n",
    "        # Intrinsic alignment parameters\n",
    "        'aia': 1.72,\n",
    "        'nia': -0.41,\n",
    "        'bia': 0.0,\n",
    "        # Redshift distributions nuisance parameters: shifts\n",
    "        'dz_1_GCphot': 0., 'dz_1_WL': 0.,\n",
    "        'dz_2_GCphot': 0., 'dz_2_WL': 0.,\n",
    "        'dz_3_GCphot': 0., 'dz_3_WL': 0.,\n",
    "        'dz_4_GCphot': 0., 'dz_4_WL': 0.,\n",
    "        'dz_5_GCphot': 0., 'dz_5_WL': 0.,\n",
    "        'dz_6_GCphot': 0., 'dz_6_WL': 0.,\n",
    "        'dz_7_GCphot': 0., 'dz_7_WL': 0.,\n",
    "        'dz_8_GCphot': 0., 'dz_8_WL': 0.,\n",
    "        'dz_9_GCphot': 0., 'dz_9_WL': 0.,\n",
    "        'dz_10_GCphot': 0., 'dz_10_WL': 0.},\n",
    "    #'theory': Cobaya's protected key of the input dictionary.\n",
    "    # Cobaya needs to ask some minimum theoretical requirements to a Boltzman Solver\n",
    "    # (UC): you can choose between CAMB or CLASS\n",
    "    # In this DEMO, we use CAMB and specify some CAMB arguments\n",
    "    # such as the number of massive neutrinos\n",
    "    # and the dark energy model\n",
    "    #\n",
    "    # ATTENTION: If you have CAMB/CLASS already installed and \n",
    "    # you are not using the likelihood conda environment \n",
    "    # or option (2) in cell (3) (Cobaya modules), you can add an extra key called 'path' within the camb dictionary\n",
    "    # to point to your already installed CAMB code\n",
    "    # NOTE: for values of the non-linear flag larger than 0, a new key is added in info['theory']['camb']['extra_args'],\n",
    "    # i.e. 'halofit_version', which contains the requested version of halofit, as described above\n",
    "    'theory': {'camb': \n",
    "               {'stop_at_error': True, \n",
    "                'extra_args':{'num_massive_neutrinos': 1,\n",
    "                              'dark_energy_model': 'ppf'}}},\n",
    "    #'sampler': Cobaya's protected key of the input dictionary.\n",
    "    # (UC): you can choose the sampler you want to use.\n",
    "    # Check Cobaya's documentation to see the list of available samplers\n",
    "    # In this DEMO, we use the 'evaluate' sampler to make a single computation of the posterior distributions\n",
    "    # Note: if you want to run a simple MCMC sampling choose 'mcmc'\n",
    "    'sampler': {'evaluate': None},  \n",
    "    # 'packages_path': Cobaya's protected key of the input dictionary.\n",
    "    # This is the variable you need to update\n",
    "    # if you are running Cobaya with cobaya_modules (option (2) above).\n",
    "    # If you are using the conda likelihood environment or option (1),\n",
    "    # please, keep the line below commented\n",
    "    #\n",
    "    #'packages_path': modules_path,\n",
    "    #\n",
    "    #'output': Cobaya's protected key of the input dictionary.\n",
    "    # Where are the results going to be stored, in case that the sampler produce output files? \n",
    "    #Â For example: chains...\n",
    "    # (UC): modify the path below within 'output' to choose a name and a directory for those files\n",
    "    'output': 'chains/my_euclid_experiment',\n",
    "    #'debug': Cobaya's protected key of the input dictionary.\n",
    "    # (UC): how much information you want Cobaya to print? If debug: True, it prints every single detail\n",
    "    # that is going on internally in Cobaya\n",
    "    'debug': False,\n",
    "    #'timing': Cobaya's protected key of the input dictionary.\n",
    "    # (UC): if timing: True, Cobaya returns how much time it took it to make a computation of the posterior\n",
    "    # and how much time take each of the modules to perform their tasks\n",
    "    'timing': True,\n",
    "    #'force': Cobaya's protected key of the input dictionary.\n",
    "    # (UC): if 'force': True, Cobaya forces deleting the previous output files, if found, with the same name\n",
    "    'force': True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'likelihood': Cobaya's protected key of the input dictionary.\n",
    "# (UC): The user can select which data wants to use for the analysis.\n",
    "# Check Cobaya's documentation to see the list of the current available data experiments\n",
    "# In this DEMO, we load the Euclid-Likelihood as an external function, and name it 'Euclid'\n",
    "info['likelihood'] = {'Euclid': \n",
    "                     {'external': EuclidLikelihood, # Likelihood Class to be read as external\n",
    "                     # Note: everything down below will overwrite the information read\n",
    "                     # in the config folder\n",
    "                     #\n",
    "                     # Select which observables want to use during the analysis\n",
    "                     'observables_selection': {\n",
    "                         'WL': {'WL': False, 'GCphot': False, 'GCspectro': False},\n",
    "                         'GCphot': {'GCphot': False, 'GCspectro': False},\n",
    "                         'GCspectro': {'GCspectro': True}\n",
    "                     },\n",
    "                     # Plot the selected observables matrx\n",
    "                     'plot_observables_selection': True,  \n",
    "                      # Non-linear flag\n",
    "                      # With this, the user can specify which non-linear model they want\n",
    "                      # For the time-being the available options are: \n",
    "                            #0 -> linear-only\n",
    "                            #1 -> Takahashi\n",
    "                            #2 -> Mead2020 (w/o baryon corrections)\n",
    "                     'NL_flag': 0,\n",
    "                     #\n",
    "                     #'data': This give specifications for the paths of the input data files\n",
    "                     'data': { \n",
    "                        #'sample' specifies the first folder below the main data folder\n",
    "                        'sample': 'ExternalBenchmark',\n",
    "                        #'spectro' and 'photo' specify paths to data files.\n",
    "                        'spectro': {\n",
    "                            # GC Spectro root name should contain z{:s} string\n",
    "                            # to enable iteration over bins\n",
    "                            'root': 'cov_power_galaxies_dk0p004_z{:s}.fits',\n",
    "                            'redshifts': [\"1.\", \"1.2\", \"1.4\", \"1.65\"]},\n",
    "                        'photo': {\n",
    "                            'ndens_GC': 'niTab-EP10-RB00.dat',\n",
    "                            'ndens_WL': 'niTab-EP10-RB00.dat',\n",
    "                            # Photometric root names should contain z{:s} string\n",
    "                            # to specify IA model\n",
    "                            'root_GC': 'Cls_{:s}_PosPos.dat',\n",
    "                            'root_WL': 'Cls_{:s}_ShearShear.dat',\n",
    "                            'root_XC': 'Cls_{:s}_PosShear.dat',\n",
    "                            'IA_model': 'zNLA',\n",
    "                            # Photometric covariances root names should contain z{:s} string\n",
    "                            # to specify how the covariance was calculated\n",
    "                            'cov_GC': 'CovMat-PosPos-{:s}-20Bins.dat',\n",
    "                            'cov_WL': 'CovMat-ShearShear-{:s}-20Bins.dat',\n",
    "                            'cov_3x2': 'CovMat-3x2pt-{:s}-20Bins.dat',\n",
    "                            'cov_model': 'Gauss'}}, \n",
    "                   \n",
    "                    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the yaml file corresponding to the Likelihood Parameters\n",
    "Cobaya needs to know which parameters the likelihood `EuclidLikelihood` expects (for example, nuisance parameters), apart from the cosmological parameters (i.e: $\\Omega_b$, $H_0$, $n_s$...) which are already known by the theory code (CAMB/CLASS). \n",
    "\n",
    "For that, a `yaml` file is generated instead of having those likelihood parameters hard-coded within `cobaya_interface.py`. To generate this `yaml` file, execute either the next cell or the next-to-next.\n",
    "\n",
    "Please, be aware that this function will only make Cobaya expect those likelihood parameters. To set some fixed values or put a prior on them, the user needs to do so within the `info` python dictionary above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likelihood.auxiliary.likelihood_yaml_handler import write_params_yaml_from_cobaya_dict, set_halofit_version\n",
    "# This function writes params.yaml using the 'params' sub-dictionary of the info dictionary,\n",
    "# stripped of cosmological parameters (such as As, ns, H0 ...)\n",
    "write_params_yaml_from_cobaya_dict(info)\n",
    "set_halofit_version(info, info['likelihood']['Euclid']['NL_flag'])\n",
    "# Now we are ready to run Cobaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way from using an hardcoded Cobaya info dictionary is loading the Cobaya configuration from a yaml file.\n",
    "# Run this cell only if you want to load the info dictionary from file.\n",
    "run_this_cell = False\n",
    "# WARNING: running this cell will overload the info dictionary defined in the previous cells\n",
    "\n",
    "from likelihood.auxiliary.likelihood_yaml_handler import get_default_configs_path\n",
    "from likelihood.auxiliary.likelihood_yaml_handler import write_params_yaml_from_model_yaml\n",
    "from likelihood.auxiliary.likelihood_yaml_handler import update_cobaya_dict_from_model_yaml\n",
    "from likelihood.auxiliary.likelihood_yaml_handler import update_cobaya_dict_with_halofit_version\n",
    "from likelihood.auxiliary.yaml_handler import yaml_read\n",
    "\n",
    "if run_this_cell:\n",
    "    # A test configuration yaml file is in 'configs/config_test.yaml'\n",
    "    # We can play with this file, or use another config file ...\n",
    "    config_test_path = get_default_configs_path() / 'config_test.yaml'\n",
    "    # Loading the dictionary from the file\n",
    "    config_test_dict = yaml_read(config_test_path)\n",
    "    info = config_test_dict['Cobaya']\n",
    "    # And read the model file name (only for this case, 'params' value is a file name where the model is specified)\n",
    "    # We can play with this model file, or use another model file ...\n",
    "    model_file = info['params']\n",
    "    # Joining the complete path for the model file\n",
    "    model_path = config_test_path.parent.joinpath(model_file)\n",
    "    # Writing params.yaml, without the cosmological parameters\n",
    "    write_params_yaml_from_model_yaml(model_path)\n",
    "    # Updating the Cobaya info dictionary from the model\n",
    "    # i.e. writing the whole 'params' dict instead of the model file name\n",
    "    update_cobaya_dict_from_model_yaml(info, model_path)\n",
    "    # Updating the Cobaya dictionary to add the halofit version corresponding to the selected NL flag\n",
    "    # This is currently 0 in the loaded yaml file, i.e. no halofit is called\n",
    "    update_cobaya_dict_with_halofit_version(info, model_path)\n",
    "\n",
    "# Now we are ready to run cobaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import Cobaya run function\n",
    "from cobaya.run import run\n",
    "\n",
    "# Let's run Cobaya\n",
    "# the function run returns\n",
    "# info_updated: an information dictionary updated with the defaults, \n",
    "# equivalent to the updated yaml file produced by the shell invocation\n",
    "# samples: a sampler object, with a sampler.products() \n",
    "# being a dictionary of results. \n",
    "# For the mcmc sampler, the dictionary contains only one chain under the key sample.\n",
    "\n",
    "info_updated, samples = run(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the printed output by Cobaya**: \n",
    "- output: it tells details about the output\n",
    "- Prior: it shows the values sampled by the prior. In this case, our parameters of interest are all fixed so Cobaya reminds that.\n",
    "- CAMB: it calls the theory code you wanted to use (CAMB/CLASS, in this case, CAMB, and where it is installed).\n",
    "\n",
    "You see these outputs repeated twice because the CLOE calls `Cobaya` internally twice, within the EuclidLikelihood, to calculate the fiducial cosmology.\n",
    "- evaluate: the 'evaluate' sampler gets initialized, looks for a point and evaluates the posterior.\n",
    "\n",
    "Note that since the option timing is True in the info dictionary, Cobaya tells you how much time it took to compute the likelihood (euclid) and CAMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: Run `Cobaya model` with Euclid-Likelihood as external likelihood \n",
    "\n",
    "**User-case**: the analysis tool `Cobaya` has a wrapper of its `evaluate` sampler (the one executed in CASE 1), called `model`, that allows to:\n",
    "\n",
    "* make an evaluation in a single point of prior, likelihood and posterior distributions\n",
    "* retrieve derived parameters and other quantities\n",
    "\n",
    "The `model` wrapper is useful for debugging as well (i.e: imagine you are running a MCMC sampling to find the best-fit values of a given model, and the MCMC chains get stuck for unknown reasons). With the `model`, you can investigate what is going on internally in `Cobaya` at each step of the sampling algorithm.\n",
    "\n",
    "Moreover, our EuclidLikelihood code, which is designed to work as an external likelihood code for `Cobaya` relies on this `model` wrapper to make the connection between `Cobaya`, the likelihood calculation and the computation of the theoretical predictions (see **CASE 2.1** for further information).\n",
    "\n",
    "In this **CASE 2**, we will see how to activate the `model` wrapper, how to use it and how to understand the output it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: import model wrapper of Cobaya \n",
    "from cobaya.model import get_model\n",
    "\n",
    "#Â The `get_model` function of Cobaya imported in the line above needs a yaml or dictionary as an argument\n",
    "# exactly the same as the function `run` in cell 9 also needs.\n",
    "#\n",
    "# We measure the time to give us an estimation of how much time it takes to make the initialization of the\n",
    "# likelihood\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# Second: create an instance of the `model` wrapper called model\n",
    "model = get_model(info)\n",
    "print('Time for initialization of the likelihood: ', time.time()-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of the printed output by Cobaya**: \n",
    "\n",
    "- Model: it tells you Cobaya is using the `model` wrapper, and it's reading the info dictionary.\n",
    "- Prior: it shows the values sampled by the prior. In this case, our parameters of interest are all fixed so Cobaya reminds that.\n",
    "- CAMB: it calls the theory code you wanted to use (CAMB/CLASS, in this case, CAMB, and where it is installed).\n",
    "\n",
    "You see these outputs repeated twice because the CLOE calls Cobaya internally twice, within the EuclidLikelihood, to calculate the fiducial cosmology.\n",
    "\n",
    "It takes around 10 seconds to initialize the likelihood (reading OU-LE3 data and computing fiducial cosmology) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalities of the `model` wrapper:\n",
    "As mentioned above, we can get an insight of what `Cobaya` is doing using the `model` object. We can ask, for instance:\n",
    " * (1) which quantities were **required** by the likelihood code and asked to the Boltzman solver through `Cobaya`\n",
    " * (2) at which values (i.e: redshift, scales...) those requirements were **requested**.\n",
    " \n",
    "To see how to ask for these quantities, execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Requirements needed by the likelihood code.\n",
    "# That means, which quantities are we asking to the Boltzman (CAMB/CLASS) through Cobaya?\n",
    "print('\\n Requirements \\n')\n",
    "print(model.provider.requirement_providers)\n",
    "# (2) At which values have the requirements been requested (redshift, scales...)?\n",
    "print('\\n Requested \\n')\n",
    "print(model.requested())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.provider.requirement_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (3) With the `model` wrapper you can also make an evaluation of the prior, likelihood and posterior distributions\n",
    "\n",
    "ATTENTION: we initialized the `model` wrapper by reading the `info` dictionary above. This `info` dictionary has almost all the parameters of interest fixed (the only sampled parameters is $n_s$). Therefore, to make an evaluation of the probability distributions (priors, likelihoods and posterior), you need:\n",
    "\n",
    "* First: get a point of the sampled parameters from the prior distribution \n",
    "* Second: pass this point to the logposterior method\n",
    "\n",
    "See comments in the cell below to understand how to retrieve the values of these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the moment, we are sampling only ns\n",
    "# if there are sampled parameters, we need first to obtain a value from the prior\n",
    "# i.e: (FIRST)\n",
    "point = dict(zip(model.parameterization.sampled_params(),\n",
    "                 model.prior.sample(ignore_external=True)[0]))\n",
    "t1 = time.time()\n",
    "# (3) Make a computation of the logposterior on that point\n",
    "logposterior = model.logposterior(point)\n",
    "# If there were no sampled parameters, you can simply do\n",
    "#logposterior = model.logposterior({})\n",
    "t2 = time.time()\n",
    "\n",
    "# Note that we are measuring the time for illustration purposes only.\n",
    "\n",
    "print('Time to compute the logposterior: ', t2-t1)\n",
    "print('Full log-posterior:')\n",
    "print('   logposterior: %g' % logposterior.logpost)\n",
    "print('   logpriors: %r' % dict(zip(list(model.prior), logposterior.logpriors)))\n",
    "print('   loglikelihoods: %r' % dict(zip(list(model.likelihood), logposterior.loglikes)))\n",
    "print('   derived params: %r' % dict(zip(list(model.parameterization.derived_params()), logposterior.derived)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2.1: EuclidLikelihood package\n",
    "\n",
    "**User-case**: this case allows the user to go one level deeper down into the CLOE code, so that the user can retrieve and plot:\n",
    "\n",
    "* Benchmark data used as mock data during the calculation of the likelihood. For instance:\n",
    "    * $n(z)$: galaxy density distributions\n",
    "* Cosmological quantities provided by the Boltzman solver through `Cobaya`. For example:\n",
    "    * $H(z)$: Hubble factor\n",
    "    * $r(z)$, $D_A$: comoving and angular diameter distances\n",
    "    * $\\sigma_8$, $f\\sigma_8$: amplitude of the (linear) power spectrum on the scale of 8 $h^{-1} Mpc$, and the product of the growth rate times the amplitude of the power spectrum at that same scale.\n",
    "* Internal cosmological quantities computed by the EuclidLikelihood package itself:\n",
    "    * $D(z)$, $f(z)$: growth factor and growth rate\n",
    "    * $P_m, P_{gg}, P_{g\\delta}, P_{\\delta i}, P_{gi}, P_{ii}$: matter power spectrum obtained by the Boltzman solver by `Cobaya` and different power spectra\n",
    "* Theoretical predictions of the photometric and spectroscopic observables\n",
    "    * $W_i^{GC}, W_i^{\\gamma}, W_i^{IA}$: window functions or kernel for Galaxy Clustering (GC), Shear ($\\gamma$) and Intrinsic Alignment.\n",
    "    * $C_\\ell$: angular power spectra\n",
    "    * $P_\\ell$: Legendre multiples\n",
    "* computation of the $\\chi^2$\n",
    "\n",
    "To be able to access all these quantities and get a grasp of what EuclidLikelihood actually does, **you need to have loaded an instance of the `model` wrapper of Cobaya (explained in CASE 2)**. In reality, what we are doing in this **CASE 2.1** is to reproduce the steps that are done internally by `Cobaya` at each step of the sampling procedure within the file `cobaya_interface.py` of the likelihood package. Therefore, understanding **CASE 2.1** will also help the user to understand the details of the EuclidLikelihood source code and structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the class EuclidLikelihood\n",
    "like = EuclidLikelihood()\n",
    "\n",
    "# Initialize default parameters for redshift, k-array, fiducial cosmology...\n",
    "like.initialize()\n",
    "\n",
    "# Get the cosmo_dictionary where all the cosmology + theory parameters are saved\n",
    "# ATTENTION: as explained above, you need to pass the `cobaya wrapper model` initialized \n",
    "#Â in CASE 2 as an argument of the function, as well as the parameters of your theory.\n",
    "# In CASE 1, when only Cobaya run is used, it creates internally this `model` instance itself\n",
    "like.passing_requirements(model, **model.provider.params)\n",
    "\n",
    "# Update the cosmology dictionary with interpolators + basic quantities such as\n",
    "# P_gg, P_delta...\n",
    "like.cosmo.update_cosmo_dic(like.cosmo.cosmo_dic['z_win'], 0.05)\n",
    "\n",
    "# Show what the cosmo_dic actually contains\n",
    "print('\\nKeys of the cosmo_dic: \\n', list(like.cosmo.cosmo_dic.keys()))\n",
    "print('\\nKeys of the nuisance params within cosmo_dic: \\n', list(like.cosmo.cosmo_dic['nuisance_parameters'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also access the quantities of the euclike module as follows:\n",
    "# This function will return the loglike\n",
    "loglike = like.likefinal.loglike(like.cosmo.cosmo_dic, like.fiducial_cosmology.cosmo_dic)\n",
    "# This loglike agrees with the one read by Cobaya if the Likelihood external code works fine\n",
    "print('loglike: ', loglike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the computation of the chi2, you can access the following quantities of the euclike module\n",
    "print('\\nList of attributes of the euclike object: \\n', list(vars(like.likefinal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print, for instance, the mean of the redshift bins used in the computation\n",
    "print(like.likefinal.zkeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot internal quantities and cosmological observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the background quantities of cosmo_dic\n",
    "# See http://pf-ist-likelihood.pages.euclid-sgs.uk/likelihood-implementation/likelihood.cosmo.cosmology.html\n",
    "# for extra information\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18,10))\n",
    "fig.suptitle('Background quantities')\n",
    "axs[0, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['H_z_func'](like.cosmo.cosmo_dic['z_win']))\n",
    "axs[0, 0].set_xlabel(r'$z$')\n",
    "axs[0, 0].set_ylabel(r'$H(z)$ $\\left[ \\frac{km}{s\\times Mpc}\\right]$')\n",
    "axs[0, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['d_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              label = r'$D_A(z)$ $[Mpc]$')\n",
    "axs[0, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['r_z_func'](like.cosmo.cosmo_dic['z_win']), '--',\n",
    "              label = r'$r(z)$')\n",
    "axs[0, 1].set_xlabel(r'$z$')\n",
    "axs[0, 1].legend(frameon=False)\n",
    "axs[1, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['sigma8_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              label = r'$\\sigma_8(z)$')\n",
    "axs[1, 0].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['fsigma8_z_func'](like.cosmo.cosmo_dic['z_win']),\n",
    "              '--', label = r'$f\\sigma_8(z)$')\n",
    "axs[1, 0].set_xlabel(r'$z$')\n",
    "axs[1, 0].legend(frameon=False)\n",
    "axs[1, 1].plot(like.cosmo.cosmo_dic['z_win'], like.cosmo.cosmo_dic['D_z_k'],\n",
    "              label = r'$D(z)$')\n",
    "axs[1, 1].plot(like.cosmo.cosmo_dic['z_win'], \n",
    "               like.cosmo.cosmo_dic['f_z'](like.cosmo.cosmo_dic['z_win']),\n",
    "              '--', label = r'$f = f\\sigma_8/\\sigma_8$')\n",
    "axs[1, 1].set_xlabel(r'$z$')\n",
    "axs[1, 1].legend(frameon=False)\n",
    "plt.subplots_adjust(top=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the matter power spectrum and other spectra quantities\n",
    "# 'Pgg_spectro', 'Pgg_phot', 'Pgdelta_phot', 'Pgdelta_spectro', 'Pii', 'Pdeltai', 'Pgi_phot', 'Pgi_spectro'\n",
    "# See http://pf-ist-likelihood.pages.euclid-sgs.uk/likelihood-implementation/likelihood.cosmo.cosmology.html\n",
    "# for extra information\n",
    "\n",
    "# WARNING: AT THE MOMENT, THE LARGE SCALES (small k values) in the power spectra are not physical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fig, axs = plt.subplots(9, 2, figsize=(20,47))\n",
    "fig.suptitle('Spectra')\n",
    "ks=np.logspace(-5, 0, 100)\n",
    "axs[0, 0].loglog(ks, like.cosmo.cosmo_dic['Pk_delta'].P(like.cosmo.cosmo_dic['z_win'][0], ks), 'o', \n",
    "           label=r\"z = {:.2f}\".format(like.cosmo.cosmo_dic['z_win'][0]))\n",
    "axs[0, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[0, 0].set_ylabel(r'$P_m [Mpc^{-3}]$')\n",
    "axs[0, 0].legend(frameon=False)\n",
    "#------\n",
    "axs[0, 1].loglog(ks, like.cosmo.cosmo_dic['Pk_delta'].P(like.cosmo.cosmo_dic['z_win'][-1], ks), 'o', \n",
    "           label=r\"z = {:.2f}\".format(like.cosmo.cosmo_dic['z_win'][-1]))\n",
    "axs[0, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[0, 1].set_ylabel(r'$P_m [Mpc^{-3}]$')\n",
    "axs[0, 1].legend(frameon=False)\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[1, 0].loglog(k, like.cosmo.cosmo_dic['Pgg_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][25], k, 1), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][25]) if i == 0 else \"\")\n",
    "    axs[1, 1].loglog(k, like.cosmo.cosmo_dic['Pgg_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][35], k, 1), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][35]) if i == 0 else \"\")\n",
    "axs[1, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[1, 0].set_ylabel(r'$P_{gg}^{spectro} [Mpc^{-3}]$')\n",
    "axs[1, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[1, 1].set_ylabel(r'$P_{gg}^{spectro} [Mpc^{-3}]$')\n",
    "axs[1, 0].legend(frameon=False)\n",
    "axs[1, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[2, 0].loglog(k, like.cosmo.cosmo_dic['Pgg_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[2, 1].loglog(k, like.cosmo.cosmo_dic['Pgg_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[2, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[2, 0].set_ylabel(r'$P_{gg}^{phot} [Mpc^{-3}]$')\n",
    "axs[2, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[2, 1].set_ylabel(r'$P_{gg}^{phot} [Mpc^{-3}]$')\n",
    "axs[2, 0].legend(frameon=False)\n",
    "axs[2, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[3, 0].loglog(k, like.cosmo.cosmo_dic['Pgdelta_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][25], k, 1), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][25]) if i == 0 else \"\")\n",
    "    axs[3, 1].loglog(k, like.cosmo.cosmo_dic['Pgdelta_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][35], k, 1), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][35]) if i == 0 else \"\")\n",
    "axs[3, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[3, 0].set_ylabel(r'$P_{g\\delta}^{spectro} [Mpc^{-3}]$')\n",
    "axs[3, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[3, 1].set_ylabel(r'$P_{g\\delta}^{spectro} [Mpc^{-3}]$')\n",
    "axs[3, 0].legend(frameon=False)\n",
    "axs[3, 1].legend(frameon=False)\n",
    "\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[4, 0].loglog(k, like.cosmo.cosmo_dic['Pgdelta_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[4, 1].loglog(k, like.cosmo.cosmo_dic['Pgdelta_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[4, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[4, 0].set_ylabel(r'$P_{g\\delta}^{phot} [Mpc^{-3}])$')\n",
    "axs[4, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[4, 1].set_ylabel(r'$P_{g\\delta}^{phot} [Mpc^{-3}]$')\n",
    "axs[4, 0].legend(frameon=False)\n",
    "axs[4, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[5, 0].loglog(k, like.cosmo.cosmo_dic['Pii'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'ro', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[5, 1].loglog(k, like.cosmo.cosmo_dic['Pii'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'ro', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[5, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[5, 0].set_ylabel(r'$P_{ii} [Mpc^{-3}]$')\n",
    "axs[5, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[5, 1].set_ylabel(r'$P_{ii} [Mpc^{-3}]$')\n",
    "axs[5, 0].legend(frameon=False)\n",
    "axs[5, 1].legend(frameon=False)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[6, 0].plot(k, like.cosmo.cosmo_dic['Pdeltai'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'bo', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[6, 1].plot(k, like.cosmo.cosmo_dic['Pdeltai'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'bo', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[6, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[6, 0].set_ylabel(r'$P_{\\delta i} [Mpc^{-3}]$')\n",
    "axs[6, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[6, 1].set_ylabel(r'$P_{\\delta i} [Mpc^{-3}]$')\n",
    "axs[6, 0].legend(frameon=False, loc=4)\n",
    "axs[6, 1].legend(frameon=False, loc=4)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[7, 0].plot(k, like.cosmo.cosmo_dic['Pgi_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[7, 1].plot(k, like.cosmo.cosmo_dic['Pgi_phot'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'go', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[7, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[7, 0].set_ylabel(r'$P_{gi}^{phot} [Mpc^{-3}]$')\n",
    "axs[7, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[7, 1].set_ylabel(r'$P_{gi}^{phot} [Mpc^{-3}]$')\n",
    "axs[7, 0].legend(frameon=False, loc=4)\n",
    "axs[7, 1].legend(frameon=False, loc=4)\n",
    "\n",
    "#------\n",
    "for i, k in enumerate(ks):\n",
    "    axs[8, 0].plot(k, like.cosmo.cosmo_dic['Pgi_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][0], k), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][0]) if i == 0 else \"\")\n",
    "    axs[8, 1].plot(k, like.cosmo.cosmo_dic['Pgi_spectro'](\n",
    "    like.cosmo.cosmo_dic['z_win'][-1], k), 'ko', label=r\"z = {:.2f}\".format(\n",
    "        like.cosmo.cosmo_dic['z_win'][-1]) if i == 0 else \"\")\n",
    "axs[8, 0].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[8, 0].set_ylabel(r'$P_{gi}^{spectro} [Mpc^{-3}]$')\n",
    "axs[8, 1].set_xlabel(r'$k$ $[Mpc^{-1}]$')\n",
    "axs[8, 1].set_ylabel(r'$P_{gi}^{spectro} [Mpc^{-3}]$')\n",
    "axs[8, 0].legend(frameon=False, loc=4)\n",
    "axs[8, 1].legend(frameon=False, loc=4)\n",
    "\n",
    "plt.subplots_adjust(top=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the initial data read by the like_calc module (class Euclike). \n",
    "# This data is at the moment the fiducial data store within the data folder of the repository\n",
    "\n",
    "# i.e: let's plot the galaxy distributions for GC-photo(z) and WL (AT THE MOMENT, THEY ARE THE SAME)\n",
    "zs = np.linspace(0, 4, 1000)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18,17))\n",
    "for key, value in like.likefinal.data_ins.nz_dict_GC_Phot.items():\n",
    "    axs[0].plot(zs, value(zs), label = key)\n",
    "for key, value in like.likefinal.data_ins.nz_dict_WL.items():\n",
    "    axs[1].plot(zs, value(zs), label = key)\n",
    "axs[0].set_xlabel(r'$z$')\n",
    "axs[0].set_ylabel(r'$n(z)$ $[sr^{-1}]$')\n",
    "axs[0].set_title(r'$GC-photo(z)$')\n",
    "axs[0].legend(frameon=False, ncol=2)\n",
    "axs[1].set_xlabel(r'$z$')\n",
    "axs[1].set_ylabel(r'$n(z)$ $[sr^{-1}]$')\n",
    "axs[1].set_title(r'$WL$')\n",
    "axs[1].legend(frameon=False, ncol=2);\n",
    "#plt.subplots_adjust(top=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the window functions for the photometric observables\n",
    "# For that, you need to import the photo class and read the cosmology dictionary and the n(z) distributions above\n",
    "from likelihood.photometric_survey.photo import Photo\n",
    "photo = Photo(like.cosmo.cosmo_dic, like.likefinal.data_ins.nz_dict_WL, like.likefinal.data_ins.nz_dict_GC_Phot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "color = list(mcolors.TABLEAU_COLORS.values())\n",
    "fig, axs = plt.subplots(3, 1, figsize=(18,12))\n",
    "for i in range(0, 10):\n",
    "    print('bin: {}'.format(i+1))\n",
    "    axs[0].plot(zs, photo.GC_window(zs, i+1), '-', label='n{}'.format(i+1))\n",
    "    axs[1].plot(photo.z_winterp, photo.WL_window(i+1), '.', color = color[i], label='n{}'.format(i+1) if i == 0 else \"\")\n",
    "    axs[2].plot(zs, photo.IA_window(zs, i+1), label='n{}'.format(i+1))\n",
    "axs[0].set_xlabel(r'$z$')\n",
    "axs[0].set_ylabel(r'$W_i^{GC-photo}$ $[Mpc^{-1}]$')\n",
    "axs[0].legend(frameon=False, ncol=2)\n",
    "axs[1].set_xlabel(r'$z$')\n",
    "axs[1].set_ylabel(r'$W_i^{\\gamma}$ $[Mpc^{-1}]$')\n",
    "axs[1].legend(frameon=False, ncol=2)\n",
    "axs[2].set_xlabel(r'$z$')\n",
    "axs[2].set_ylabel(r'$W_i^{IA}$ $[Mpc^{-1}]$')\n",
    "axs[2].legend(frameon=False, ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Euclid final observables\n",
    "\n",
    "We can use the auxiliary module of the CLOE to plot the final observables. **Have in mind that the predicted values for the angular power spectra will probably not agree with the fiducial plotted values from the Benchmark data as we are currently sampling $n_s$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the Plotter Class\n",
    "from likelihood.auxiliary.plotter import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model.parameterization.sampled_params():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak-Lensing angular power spectrum according to the IST:L recipe \n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        pl_label = 'ns'#'{}={:.4f}'.format(param, model.parameterization.sampled_params()[param])\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "pl_label = 'ns'\n",
    "pl_inst = Plotter(cosmo_dic=like.cosmo.cosmo_dic, data=like.likefinal.data)\n",
    "ax1 = pl_inst.plot_external_Cl_phot(1, 1, ax1, probe='WL', pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), 1, 1, ax1, probe='WL', pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel(r'$C_\\ell$ $[sr^{-1}]$', fontsize=20)\n",
    "ax1.set_xscale('linear')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('Weak-Lensing bin1')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC-photo(z) angular power spectrum\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        pl_label = '{}={:.4f}'.format(param, model.parameterization.sampled_params()[param])\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "ax1 = pl_inst.plot_external_Cl_phot(1, 1, ax1, probe='GC-Phot', pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_Cl_phot(np.logspace(1, 3.6, 10), 1, 1, ax1, probe='GC-Phot', pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel(r'$C_\\ell$ $[sr^{-1}]$', fontsize=20)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('GC-photo(z) bin1')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation WL x GC-photo(z) angular power spectrum\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        pl_label = '{}={:.4f}'.format(param, model.parameterization.sampled_params()[param])\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "ax1 = pl_inst.plot_external_Cl_XC(1, 1, ax1, pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_Cl_XC(np.logspace(1, 3.6, 10), 1, 1, ax1, pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$\\ell$', fontsize=20)\n",
    "ax1.set_ylabel(r'$C_\\ell$ $[sr^{-1}]$', fontsize=20)\n",
    "ax1.set_xscale('log')\n",
    "#ax1.set_yscale('log')\n",
    "ax1.set_title('WL x GC-photo(z) bin1')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC-spectro observable\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "for param in model.parameterization.sampled_params().keys():\n",
    "        pl_label = '{}={:.4f}'.format(param, model.parameterization.sampled_params()[param])\n",
    "        print('WARNING: param {} is being sampled! Possible mismatch between benchmark and theoretical prediction'.format(param))\n",
    "ax1 = pl_inst.plot_external_GC_spectro(\"1.2\", 2, ax1, pl_label='Benchmark')\n",
    "ax1 = pl_inst.plot_GC_spectro_multipole(1.2, np.linspace(0.01, 0.5), 2, ax1, pl_colour='r', pl_linestyle='--', pl_label=pl_label)\n",
    "ax1.set_xlabel(r'$k$ $[Mpc^{-1}]$', fontsize=20)\n",
    "ax1.set_ylabel(r'$P_\\ell$', fontsize=20)\n",
    "ax1.set_xscale('linear')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('GC-spectro bin1')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
